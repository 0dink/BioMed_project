{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC, OneClassSVM\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reader: 1069 | # samples 300\n",
      "reader: 19 | # samples 300\n",
      "reader: 201 | # samples 300\n",
      "reader: 250 | # samples 300\n",
      "reader: 254 | # samples 300\n",
      "reader: 26 | # samples 300\n",
      "reader: 27 | # samples 300\n",
      "reader: 289 | # samples 300\n",
      "reader: 298 | # samples 300\n",
      "reader: 311 | # samples 300\n",
      "reader: 32 | # samples 300\n",
      "reader: 3240 | # samples 300\n",
      "reader: 39 | # samples 300\n",
      "reader: 40 | # samples 300\n",
      "reader: 4297 | # samples 300\n",
      "reader: 60 | # samples 300\n",
      "reader: 78 | # samples 300\n",
      "reader: 7800 | # samples 300\n",
      "reader: 83 | # samples 300\n",
      "reader: 87 | # samples 300\n"
     ]
    }
   ],
   "source": [
    "features = \"mfcc_20_format_freq\"\n",
    "\n",
    "with open(f\"../../data/extracted_features_v2/{features}.pickle\", \"rb\") as file:\n",
    "   mfcc_stats_dict = pickle.load(file)\n",
    "\n",
    "for reader in mfcc_stats_dict.keys():\n",
    "    print(f\"reader: {reader} | # samples {len(mfcc_stats_dict[reader])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(reader, max, split=.8):\n",
    "    mfccs = [mfcc for mfcc in reader]\n",
    "    mfccs = mfccs[0:max]\n",
    "\n",
    "    mfccs_train = mfccs[0:round(len(mfccs)*split)]\n",
    "    mfccs_test  = mfccs[round(len(mfccs)*split):len(mfccs)]\n",
    "\n",
    "    return mfccs_train, mfccs_test\n",
    "\n",
    "def partition_wrapper(data_dictionary, max):\n",
    "    test_dict = {}\n",
    "    train_dict = {}\n",
    "\n",
    "    for key in data_dictionary.keys():\n",
    "        train, test = partition_data(data_dictionary[key], max)\n",
    "        train_dict[key] = train\n",
    "        test_dict[key] = test\n",
    "\n",
    "    return train_dict, test_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_indices(n, x, seed=42):\n",
    "    if n > x + 1:\n",
    "        raise ValueError(\"Cannot generate more unique numbers than the specified range.\")\n",
    "    \n",
    "    random.seed(seed)  # Set the seed for reproducibility\n",
    "    return random.sample(range(0, x), n)\n",
    "\n",
    "def average_score(model,test_data):\n",
    "    scores = []\n",
    "    for data_point in test_data:\n",
    "        scores.append(model.score(data_point.reshape(1,-1)))\n",
    "    return scores, np.mean(scores)\n",
    "\n",
    "def average_score_compare(model_dict, test_data_dict):\n",
    "    for model_key in model_dict.keys():\n",
    "        score_list = []\n",
    "        for data_key in test_data_dict.keys():\n",
    "            _, avg_score = average_score(model_dict[model_key], test_data_dict[data_key])\n",
    "            avg_score = round(float(avg_score), 3)\n",
    "            score_list.append((data_key, avg_score))\n",
    "        print(f\"model {model_key}: {score_list}\")\n",
    "\n",
    "def generate_binary_test_set(data_dict, key):\n",
    "    if key not in data_dict:\n",
    "        raise KeyError(f\"The key '{key}' does not exist in the dictionary.\")\n",
    "    \n",
    "    true_values = data_dict[key] # Get the list corresponding to the key\n",
    "\n",
    "    num_other_classes = len(data_dict.keys()) - 1\n",
    "    num_of_true_samples = len(true_values)\n",
    "\n",
    "    samples_per_class = num_of_true_samples // num_other_classes\n",
    "    # print(f\"samples per class: {samples_per_class}\")\n",
    "\n",
    "    random_indices = generate_random_indices(samples_per_class, num_of_true_samples)\n",
    "\n",
    "    test_set = true_values.copy()  # Start with the list for the specified key\n",
    "    \n",
    "    for k, v in data_dict.items():\n",
    "        if k != key:  # Skip the list that corresponds to the key\n",
    "            for i in random_indices:\n",
    "                test_set.append(v[i])\n",
    "\n",
    "    return test_set, num_of_true_samples\n",
    "\n",
    "def generate_metrics(model_dict, data_dict, key):\n",
    "   \"\"\"\n",
    "   Returns metrics for One-Class SVM using predict():\n",
    "   - [TP, FP\n",
    "      FN, TN].\n",
    "   \"\"\"\n",
    "   \n",
    "   model = model_dict[key]\n",
    "   control_data = data_dict[key]\n",
    "\n",
    "   # Concatenate data (assuming the data_dict is structured similarly to the original code)\n",
    "   data, segments_length = generate_binary_test_set(data_dict, key)\n",
    "\n",
    "   # Ground truth: first part is non-target (0), second part is target (1)\n",
    "   ground_truth = [0] * segments_length + [1] * (len(data) - segments_length)\n",
    "   \n",
    "   # Get binary predictions (1 for inliers, -1 for outliers)\n",
    "   predicted_labels = model.predict(data)\n",
    "\n",
    "   # Convert predictions to binary labels: 1 for inliers, 0 for outliers\n",
    "   predicted_labels = [1 if label == 1 else 0 for label in predicted_labels]\n",
    "\n",
    "   # Generate confusion matrix and other metrics\n",
    "   matrix = confusion_matrix(ground_truth, predicted_labels)\n",
    "   accuracy = accuracy_score(ground_truth, predicted_labels)\n",
    "   precision = precision_score(ground_truth, predicted_labels)\n",
    "   recall = recall_score(ground_truth, predicted_labels)\n",
    "   f1 = f1_score(ground_truth, predicted_labels)\n",
    "   \n",
    "   # For ROC AUC, we use the decision function to get the scores\n",
    "   decision_scores = model.decision_function(data)\n",
    "   roc_auc = roc_auc_score(ground_truth, decision_scores)\n",
    "   fpr, tpr, _ = roc_curve(ground_truth, decision_scores)\n",
    "   \n",
    "   return matrix, accuracy, precision, recall, f1, roc_auc, fpr, tpr\n",
    "\n",
    "def save_metrics(model_dict, data_dict, output_file=\"./metrics.txt\"):\n",
    "    metric_dict = {}\n",
    "    \n",
    "    for key in model_dict.keys():\n",
    "        # threshold, matrix, accuracy, precision, recall, f1, roc_auc, _, _ = generate_metrics(model_dict, data_dict, key)\n",
    "        matrix, accuracy, precision, recall, f1, roc_auc, _, _ = generate_metrics(model_dict, data_dict, key)\n",
    "\n",
    "        if isinstance(matrix, np.ndarray):\n",
    "            matrix = matrix.tolist()\n",
    "\n",
    "        metric_dict[key] = {\n",
    "            #'threshold' : threshold,\n",
    "            'matrix': matrix,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'roc_auc': roc_auc\n",
    "        }\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        for key, metrics in metric_dict.items():\n",
    "            f.write(f\"{key}:\\n\")\n",
    "            #f.write(f\"    threshold: {round(metrics['threshold'], 4)}\\n\")\n",
    "            f.write(f\"    accuracy: {round(metrics['accuracy'], 4)}\\n\")\n",
    "            f.write(f\"    precision: {round(metrics['precision'], 4)}\\n\")\n",
    "            f.write(f\"    recall: {round(metrics['recall'], 4)}\\n\")\n",
    "            f.write(f\"    F1-score: {round(metrics['f1'], 4)}\\n\")\n",
    "            f.write(f\"    ROC AUC: {round(metrics['roc_auc'], 4)}\\n\")\n",
    "            \n",
    "            # Formatting the matrix\n",
    "            f.write(f\"    matrix:\\n\")\n",
    "            for row in metrics['matrix']:\n",
    "                f.write(f\"        {row}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    return metric_dict\n",
    "\n",
    "def plot_roc_all(model_dict, data_dict, features_used=\"\", save_dir=None):\n",
    "    plt.figure(figsize=(13, 11))\n",
    "\n",
    "    for key in model_dict.keys():\n",
    "        _, _, _, _, _, _, roc_auc, fpr, tpr, = generate_metrics(model_dict, data_dict, key)\n",
    "        plt.plot(fpr, tpr, label=f'{key} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random chance\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curves for All Models {features_used}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    if save_dir:    \n",
    "        plt.savefig(os.path.join(save_dir, f\"{features_used}.png\"))\n",
    "    plt.show()\n",
    "    plt.close()  # Close plot to prevent overlap in successive calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(train_dict, key):\n",
    "    training_data, segments_length = generate_binary_test_set(train_dict, key)\n",
    "    training_data = np.vstack(training_data)\n",
    "    ground_truth = [0] * segments_length + [1] * (len(training_data) - segments_length)\n",
    "    model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "    return(model.fit(training_data, ground_truth))\n",
    "\n",
    "def train_wrapper(train_dict):\n",
    "    model_dict = {}\n",
    "\n",
    "    for key in train_dict.keys():\n",
    "        model_dict[key] = train_svm(train_dict, key)\n",
    "    \n",
    "    return(model_dict)\n",
    "\n",
    "def train_one_class_svm(train_data):\n",
    "    model = OneClassSVM(kernel=\"rbf\", nu=0.1, gamma=\"auto\")\n",
    "    return model.fit(train_data)\n",
    "\n",
    "def train_one_class_svm_wrapper(train_dict):\n",
    "    model_dict = {}\n",
    "\n",
    "    for key in train_dict.keys():\n",
    "        model_dict[key] = train_svm(train_dict, key)\n",
    "    \n",
    "    return(model_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = partition_wrapper(mfcc_stats_dict, 300)\n",
    "speaker_models = train_wrapper(train_data)\n",
    "speaker_models_one_class = train_one_class_svm_wrapper(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1069': {'matrix': [[60, 0], [4, 53]],\n",
       "  'accuracy': 0.9658119658119658,\n",
       "  'precision': np.float64(1.0),\n",
       "  'recall': np.float64(0.9298245614035088),\n",
       "  'f1': np.float64(0.9636363636363636),\n",
       "  'roc_auc': np.float64(0.9982456140350877)},\n",
       " '19': {'matrix': [[59, 1], [2, 55]],\n",
       "  'accuracy': 0.9743589743589743,\n",
       "  'precision': np.float64(0.9821428571428571),\n",
       "  'recall': np.float64(0.9649122807017544),\n",
       "  'f1': np.float64(0.9734513274336283),\n",
       "  'roc_auc': np.float64(0.9953216374269005)},\n",
       " '201': {'matrix': [[57, 3], [14, 43]],\n",
       "  'accuracy': 0.8547008547008547,\n",
       "  'precision': np.float64(0.9347826086956522),\n",
       "  'recall': np.float64(0.7543859649122807),\n",
       "  'f1': np.float64(0.8349514563106796),\n",
       "  'roc_auc': np.float64(0.934795321637427)},\n",
       " '250': {'matrix': [[39, 21], [13, 44]],\n",
       "  'accuracy': 0.7094017094017094,\n",
       "  'precision': np.float64(0.676923076923077),\n",
       "  'recall': np.float64(0.7719298245614035),\n",
       "  'f1': np.float64(0.7213114754098361),\n",
       "  'roc_auc': np.float64(0.7970760233918129)},\n",
       " '254': {'matrix': [[28, 32], [1, 56]],\n",
       "  'accuracy': 0.717948717948718,\n",
       "  'precision': np.float64(0.6363636363636364),\n",
       "  'recall': np.float64(0.9824561403508771),\n",
       "  'f1': np.float64(0.7724137931034483),\n",
       "  'roc_auc': np.float64(0.9026315789473685)},\n",
       " '26': {'matrix': [[57, 3], [5, 52]],\n",
       "  'accuracy': 0.9316239316239316,\n",
       "  'precision': np.float64(0.9454545454545454),\n",
       "  'recall': np.float64(0.9122807017543859),\n",
       "  'f1': np.float64(0.9285714285714286),\n",
       "  'roc_auc': np.float64(0.9836257309941521)},\n",
       " '27': {'matrix': [[60, 0], [18, 39]],\n",
       "  'accuracy': 0.8461538461538461,\n",
       "  'precision': np.float64(1.0),\n",
       "  'recall': np.float64(0.6842105263157895),\n",
       "  'f1': np.float64(0.8125),\n",
       "  'roc_auc': np.float64(0.9014619883040936)},\n",
       " '289': {'matrix': [[58, 2], [3, 54]],\n",
       "  'accuracy': 0.9572649572649573,\n",
       "  'precision': np.float64(0.9642857142857143),\n",
       "  'recall': np.float64(0.9473684210526315),\n",
       "  'f1': np.float64(0.9557522123893806),\n",
       "  'roc_auc': np.float64(0.9950292397660818)},\n",
       " '298': {'matrix': [[56, 4], [12, 45]],\n",
       "  'accuracy': 0.8632478632478633,\n",
       "  'precision': np.float64(0.9183673469387755),\n",
       "  'recall': np.float64(0.7894736842105263),\n",
       "  'f1': np.float64(0.8490566037735849),\n",
       "  'roc_auc': np.float64(0.9771929824561403)},\n",
       " '311': {'matrix': [[53, 7], [13, 44]],\n",
       "  'accuracy': 0.8290598290598291,\n",
       "  'precision': np.float64(0.8627450980392157),\n",
       "  'recall': np.float64(0.7719298245614035),\n",
       "  'f1': np.float64(0.8148148148148148),\n",
       "  'roc_auc': np.float64(0.9383040935672514)},\n",
       " '32': {'matrix': [[59, 1], [10, 47]],\n",
       "  'accuracy': 0.905982905982906,\n",
       "  'precision': np.float64(0.9791666666666666),\n",
       "  'recall': np.float64(0.8245614035087719),\n",
       "  'f1': np.float64(0.8952380952380953),\n",
       "  'roc_auc': np.float64(0.9576023391812866)},\n",
       " '3240': {'matrix': [[59, 1], [9, 48]],\n",
       "  'accuracy': 0.9145299145299145,\n",
       "  'precision': np.float64(0.9795918367346939),\n",
       "  'recall': np.float64(0.8421052631578947),\n",
       "  'f1': np.float64(0.9056603773584906),\n",
       "  'roc_auc': np.float64(0.9558479532163742)},\n",
       " '39': {'matrix': [[55, 5], [9, 48]],\n",
       "  'accuracy': 0.8803418803418803,\n",
       "  'precision': np.float64(0.9056603773584906),\n",
       "  'recall': np.float64(0.8421052631578947),\n",
       "  'f1': np.float64(0.8727272727272727),\n",
       "  'roc_auc': np.float64(0.9380116959064326)},\n",
       " '40': {'matrix': [[55, 5], [8, 49]],\n",
       "  'accuracy': 0.8888888888888888,\n",
       "  'precision': np.float64(0.9074074074074074),\n",
       "  'recall': np.float64(0.8596491228070176),\n",
       "  'f1': np.float64(0.8828828828828829),\n",
       "  'roc_auc': np.float64(0.9713450292397661)},\n",
       " '4297': {'matrix': [[59, 1], [11, 46]],\n",
       "  'accuracy': 0.8974358974358975,\n",
       "  'precision': np.float64(0.9787234042553191),\n",
       "  'recall': np.float64(0.8070175438596491),\n",
       "  'f1': np.float64(0.8846153846153846),\n",
       "  'roc_auc': np.float64(0.9643274853801169)},\n",
       " '60': {'matrix': [[57, 3], [9, 48]],\n",
       "  'accuracy': 0.8974358974358975,\n",
       "  'precision': np.float64(0.9411764705882353),\n",
       "  'recall': np.float64(0.8421052631578947),\n",
       "  'f1': np.float64(0.8888888888888888),\n",
       "  'roc_auc': np.float64(0.9874269005847953)},\n",
       " '78': {'matrix': [[60, 0], [22, 35]],\n",
       "  'accuracy': 0.811965811965812,\n",
       "  'precision': np.float64(1.0),\n",
       "  'recall': np.float64(0.6140350877192983),\n",
       "  'f1': np.float64(0.7608695652173914),\n",
       "  'roc_auc': np.float64(0.9239766081871345)},\n",
       " '7800': {'matrix': [[60, 0], [3, 54]],\n",
       "  'accuracy': 0.9743589743589743,\n",
       "  'precision': np.float64(1.0),\n",
       "  'recall': np.float64(0.9473684210526315),\n",
       "  'f1': np.float64(0.972972972972973),\n",
       "  'roc_auc': np.float64(0.9997076023391812)},\n",
       " '83': {'matrix': [[58, 2], [9, 48]],\n",
       "  'accuracy': 0.905982905982906,\n",
       "  'precision': np.float64(0.96),\n",
       "  'recall': np.float64(0.8421052631578947),\n",
       "  'f1': np.float64(0.897196261682243),\n",
       "  'roc_auc': np.float64(0.9792397660818712)},\n",
       " '87': {'matrix': [[57, 3], [9, 48]],\n",
       "  'accuracy': 0.8974358974358975,\n",
       "  'precision': np.float64(0.9411764705882353),\n",
       "  'recall': np.float64(0.8421052631578947),\n",
       "  'f1': np.float64(0.8888888888888888),\n",
       "  'roc_auc': np.float64(0.9818713450292398)}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_metrics(speaker_models, test_data, output_file=f\"./metrics/SVM/{features}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1069': {'matrix': [[60, 0], [4, 53]],\n",
       "  'accuracy': 0.9658119658119658,\n",
       "  'precision': np.float64(1.0),\n",
       "  'recall': np.float64(0.9298245614035088),\n",
       "  'f1': np.float64(0.9636363636363636),\n",
       "  'roc_auc': np.float64(0.9982456140350877)},\n",
       " '19': {'matrix': [[59, 1], [2, 55]],\n",
       "  'accuracy': 0.9743589743589743,\n",
       "  'precision': np.float64(0.9821428571428571),\n",
       "  'recall': np.float64(0.9649122807017544),\n",
       "  'f1': np.float64(0.9734513274336283),\n",
       "  'roc_auc': np.float64(0.9953216374269005)},\n",
       " '201': {'matrix': [[57, 3], [14, 43]],\n",
       "  'accuracy': 0.8547008547008547,\n",
       "  'precision': np.float64(0.9347826086956522),\n",
       "  'recall': np.float64(0.7543859649122807),\n",
       "  'f1': np.float64(0.8349514563106796),\n",
       "  'roc_auc': np.float64(0.934795321637427)},\n",
       " '250': {'matrix': [[39, 21], [13, 44]],\n",
       "  'accuracy': 0.7094017094017094,\n",
       "  'precision': np.float64(0.676923076923077),\n",
       "  'recall': np.float64(0.7719298245614035),\n",
       "  'f1': np.float64(0.7213114754098361),\n",
       "  'roc_auc': np.float64(0.7970760233918129)},\n",
       " '254': {'matrix': [[28, 32], [1, 56]],\n",
       "  'accuracy': 0.717948717948718,\n",
       "  'precision': np.float64(0.6363636363636364),\n",
       "  'recall': np.float64(0.9824561403508771),\n",
       "  'f1': np.float64(0.7724137931034483),\n",
       "  'roc_auc': np.float64(0.9026315789473685)},\n",
       " '26': {'matrix': [[57, 3], [5, 52]],\n",
       "  'accuracy': 0.9316239316239316,\n",
       "  'precision': np.float64(0.9454545454545454),\n",
       "  'recall': np.float64(0.9122807017543859),\n",
       "  'f1': np.float64(0.9285714285714286),\n",
       "  'roc_auc': np.float64(0.9836257309941521)},\n",
       " '27': {'matrix': [[60, 0], [18, 39]],\n",
       "  'accuracy': 0.8461538461538461,\n",
       "  'precision': np.float64(1.0),\n",
       "  'recall': np.float64(0.6842105263157895),\n",
       "  'f1': np.float64(0.8125),\n",
       "  'roc_auc': np.float64(0.9014619883040936)},\n",
       " '289': {'matrix': [[58, 2], [3, 54]],\n",
       "  'accuracy': 0.9572649572649573,\n",
       "  'precision': np.float64(0.9642857142857143),\n",
       "  'recall': np.float64(0.9473684210526315),\n",
       "  'f1': np.float64(0.9557522123893806),\n",
       "  'roc_auc': np.float64(0.9950292397660818)},\n",
       " '298': {'matrix': [[56, 4], [12, 45]],\n",
       "  'accuracy': 0.8632478632478633,\n",
       "  'precision': np.float64(0.9183673469387755),\n",
       "  'recall': np.float64(0.7894736842105263),\n",
       "  'f1': np.float64(0.8490566037735849),\n",
       "  'roc_auc': np.float64(0.9771929824561403)},\n",
       " '311': {'matrix': [[53, 7], [13, 44]],\n",
       "  'accuracy': 0.8290598290598291,\n",
       "  'precision': np.float64(0.8627450980392157),\n",
       "  'recall': np.float64(0.7719298245614035),\n",
       "  'f1': np.float64(0.8148148148148148),\n",
       "  'roc_auc': np.float64(0.9383040935672514)},\n",
       " '32': {'matrix': [[59, 1], [10, 47]],\n",
       "  'accuracy': 0.905982905982906,\n",
       "  'precision': np.float64(0.9791666666666666),\n",
       "  'recall': np.float64(0.8245614035087719),\n",
       "  'f1': np.float64(0.8952380952380953),\n",
       "  'roc_auc': np.float64(0.9576023391812866)},\n",
       " '3240': {'matrix': [[59, 1], [9, 48]],\n",
       "  'accuracy': 0.9145299145299145,\n",
       "  'precision': np.float64(0.9795918367346939),\n",
       "  'recall': np.float64(0.8421052631578947),\n",
       "  'f1': np.float64(0.9056603773584906),\n",
       "  'roc_auc': np.float64(0.9558479532163742)},\n",
       " '39': {'matrix': [[55, 5], [9, 48]],\n",
       "  'accuracy': 0.8803418803418803,\n",
       "  'precision': np.float64(0.9056603773584906),\n",
       "  'recall': np.float64(0.8421052631578947),\n",
       "  'f1': np.float64(0.8727272727272727),\n",
       "  'roc_auc': np.float64(0.9380116959064326)},\n",
       " '40': {'matrix': [[55, 5], [8, 49]],\n",
       "  'accuracy': 0.8888888888888888,\n",
       "  'precision': np.float64(0.9074074074074074),\n",
       "  'recall': np.float64(0.8596491228070176),\n",
       "  'f1': np.float64(0.8828828828828829),\n",
       "  'roc_auc': np.float64(0.9713450292397661)},\n",
       " '4297': {'matrix': [[59, 1], [11, 46]],\n",
       "  'accuracy': 0.8974358974358975,\n",
       "  'precision': np.float64(0.9787234042553191),\n",
       "  'recall': np.float64(0.8070175438596491),\n",
       "  'f1': np.float64(0.8846153846153846),\n",
       "  'roc_auc': np.float64(0.9643274853801169)},\n",
       " '60': {'matrix': [[57, 3], [9, 48]],\n",
       "  'accuracy': 0.8974358974358975,\n",
       "  'precision': np.float64(0.9411764705882353),\n",
       "  'recall': np.float64(0.8421052631578947),\n",
       "  'f1': np.float64(0.8888888888888888),\n",
       "  'roc_auc': np.float64(0.9874269005847953)},\n",
       " '78': {'matrix': [[60, 0], [22, 35]],\n",
       "  'accuracy': 0.811965811965812,\n",
       "  'precision': np.float64(1.0),\n",
       "  'recall': np.float64(0.6140350877192983),\n",
       "  'f1': np.float64(0.7608695652173914),\n",
       "  'roc_auc': np.float64(0.9239766081871345)},\n",
       " '7800': {'matrix': [[60, 0], [3, 54]],\n",
       "  'accuracy': 0.9743589743589743,\n",
       "  'precision': np.float64(1.0),\n",
       "  'recall': np.float64(0.9473684210526315),\n",
       "  'f1': np.float64(0.972972972972973),\n",
       "  'roc_auc': np.float64(0.9997076023391812)},\n",
       " '83': {'matrix': [[58, 2], [9, 48]],\n",
       "  'accuracy': 0.905982905982906,\n",
       "  'precision': np.float64(0.96),\n",
       "  'recall': np.float64(0.8421052631578947),\n",
       "  'f1': np.float64(0.897196261682243),\n",
       "  'roc_auc': np.float64(0.9792397660818712)},\n",
       " '87': {'matrix': [[57, 3], [9, 48]],\n",
       "  'accuracy': 0.8974358974358975,\n",
       "  'precision': np.float64(0.9411764705882353),\n",
       "  'recall': np.float64(0.8421052631578947),\n",
       "  'f1': np.float64(0.8888888888888888),\n",
       "  'roc_auc': np.float64(0.9818713450292398)}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_metrics(speaker_models_one_class, test_data, output_file=f\"./metrics/SVM/{features}_oneclass.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioMed_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
