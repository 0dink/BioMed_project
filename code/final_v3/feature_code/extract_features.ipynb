{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis,skew,mode\n",
    "from pydub import AudioSegment\n",
    "import time\n",
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths_by_subfolder(root_path):\n",
    "    result = {}\n",
    "    # Loop through each subfolder in the root path\n",
    "    for subfolder in os.listdir(root_path):\n",
    "        subfolder_path = os.path.join(root_path, subfolder)\n",
    "        \n",
    "        # Check if it is indeed a folder\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            file_paths = []\n",
    "            \n",
    "            # Loop through each subsubfolder in the subfolder\n",
    "            for subsubfolder in os.listdir(subfolder_path):\n",
    "                subsubfolder_path = os.path.join(subfolder_path, subsubfolder)\n",
    "                \n",
    "                # Check if it is indeed a folder\n",
    "                if os.path.isdir(subsubfolder_path):\n",
    "                    # Add file paths to the list\n",
    "                    for file_name in os.listdir(subsubfolder_path):\n",
    "                        file_path = os.path.join(subsubfolder_path, file_name)\n",
    "                        \n",
    "                        # Ensure it is a file\n",
    "                        if os.path.isfile(file_path):\n",
    "                            file_paths.append(file_path)\n",
    "            \n",
    "            # Add to result dictionary\n",
    "            result[subfolder] = file_paths\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_audio_paths(root_path):\n",
    "    results = {}\n",
    "    \n",
    "    for audio_path in os.listdir(root_path):\n",
    "        # Get the full path by joining root_path and audio_path\n",
    "        full_path = os.path.join(root_path, audio_path)\n",
    "        \n",
    "        # Only add files (not directories)\n",
    "        if os.path.isfile(full_path):\n",
    "            filename = os.path.basename(audio_path)\n",
    "            file_name_wo_ext, _ = os.path.splitext(filename)\n",
    "            results[file_name_wo_ext] = full_path\n",
    "\n",
    "    return results\n",
    "\n",
    "def combine_wav_files(file_dict, output_path=\"../../../data/cleaned_combined\"):\n",
    "    for key in file_dict.keys():\n",
    "        combined_audio = AudioSegment.empty()\n",
    "\n",
    "        for file_path in file_dict[key]:\n",
    "            audio = AudioSegment.from_wav(file_path)\n",
    "            combined_audio += audio\n",
    "        \n",
    "        combined_audio.export(f\"{output_path}/{key}.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio_segment(segment, sample_rate, output_file_path):\n",
    "    # Convert the numpy array back to AudioSegment\n",
    "    audio_segment = AudioSegment(\n",
    "        segment.tobytes(),\n",
    "        frame_rate=sample_rate,\n",
    "        sample_width=segment.dtype.itemsize,\n",
    "        channels=1  # Mono channel\n",
    "    )\n",
    "    \n",
    "    # Export the segment as a WAV file\n",
    "    audio_segment.export(output_file_path, format=\"wav\")\n",
    "\n",
    "# def segment_audio(audio_file_path):\n",
    "#     # Load the audio file\n",
    "#     audio = AudioSegment.from_file(audio_file_path)\n",
    "    \n",
    "#     # Set duration for each segment in milliseconds and get the sample rate\n",
    "#     segment_duration_ms = 4 * 1000  # 4 seconds in milliseconds\n",
    "#     sample_rate = audio.frame_rate\n",
    "#     samples_per_segment = segment_duration_ms * sample_rate // 1000  # Calculate samples per 4 seconds\n",
    "\n",
    "#     # Convert the entire audio to a numpy array\n",
    "#     audio_array = np.array(audio.get_array_of_samples())\n",
    "\n",
    "#     # Calculate the number of 4-second segments and trim any extra samples\n",
    "#     num_segments = len(audio_array) // samples_per_segment\n",
    "#     trimmed_audio_array = audio_array[:num_segments * samples_per_segment]\n",
    "\n",
    "#     # Reshape the array into 4-second segments\n",
    "#     segments = trimmed_audio_array.reshape(num_segments, samples_per_segment)\n",
    "    \n",
    "#     return segments, sample_rate  # Return both segments and the sample rate\n",
    "\n",
    "def segment_audio(audio_file_path):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(audio_file_path)\n",
    "    \n",
    "    # Set duration for each segment in milliseconds and get the sample rate\n",
    "    segment_duration_ms = 1 * 1000  # 4 seconds in milliseconds\n",
    "    sample_rate = audio.frame_rate\n",
    "    samples_per_segment = segment_duration_ms * sample_rate // 1000  # Calculate samples per 4 seconds\n",
    "\n",
    "    # Convert the entire audio to a numpy array\n",
    "    audio_array = np.array(audio.get_array_of_samples())\n",
    "\n",
    "    # Normalize the audio to the range [-1.0, 1.0]\n",
    "    audio_array = audio_array.astype(np.float32)  # Convert to float32\n",
    "    audio_array /= np.max(np.abs(audio_array))  # Normalize to [-1, 1]\n",
    "\n",
    "    # Calculate the number of 4-second segments and trim any extra samples\n",
    "    num_segments = len(audio_array) // samples_per_segment\n",
    "    trimmed_audio_array = audio_array[:num_segments * samples_per_segment]\n",
    "\n",
    "    # Reshape the array into 4-second segments\n",
    "    segments = trimmed_audio_array.reshape(num_segments, samples_per_segment)\n",
    "    \n",
    "    return segments, sample_rate  # Return both segments and the sample rate\n",
    "\n",
    "def segment_audio_wrapper(file_dict):\n",
    "    segment_dict = {}\n",
    "\n",
    "    for key in file_dict.keys():\n",
    "        segment_dict[key], _ = segment_audio(file_dict[key])\n",
    "        \n",
    "    return segment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_segments, sample_rate=16000):\n",
    "    \n",
    "    mfcc_time_list = []\n",
    "    feature_time_list = []\n",
    "    pitch_time_list = []\n",
    "\n",
    "    feature_list = []\n",
    "    sample_limit = 600\n",
    "    for index, segment in enumerate(audio_segments[0:sample_limit]):\n",
    "\n",
    "        mfcc_start_time = time.time()\n",
    "        mfcc_data = librosa.feature.mfcc(y=segment, sr=sample_rate, n_mfcc=20)\n",
    "        \n",
    "        mfcc_time = time.time() - mfcc_start_time\n",
    "\n",
    "        feature_start_time = time.time()\n",
    "        # Calculating various statistic measures on the MFCC coefficients\n",
    "        mean_mfcc = np.mean(mfcc_data, axis=1)\n",
    "        median_mfcc = np.median(mfcc_data, axis=1)\n",
    "        std_mfcc = np.std(mfcc_data, axis=1)\n",
    "        skew_mfcc = skew(mfcc_data, axis=1)\n",
    "        kurt_mfcc = kurtosis(mfcc_data, axis=1)\n",
    "        maximum_mfcc = np.amax(mfcc_data, axis=1)\n",
    "        minimum_mfcc = np.amin(mfcc_data, axis=1)\n",
    "        \n",
    "        feature_time = time.time() - feature_start_time\n",
    "\n",
    "\n",
    "        pitch_start_time = time.time()\n",
    "        #Pitch extraction\n",
    "        f0, voiced_flag, voiced_probs = librosa.pyin(\n",
    "            segment, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')\n",
    "        )\n",
    "        \n",
    "        # Handle NaNs in pitch\n",
    "        if np.all(np.isnan(f0)):\n",
    "            mean_pitch, median_pitch = 0, 0  # Set default if no pitch is detected\n",
    "        else:\n",
    "            mean_pitch = np.nanmean(f0)  # Mean pitch, ignoring NaNs\n",
    "            median_pitch = np.nanmedian(f0)  # Median pitch, ignoring NaNs\n",
    "\n",
    "        pitch_time = time.time() - pitch_start_time\n",
    "\n",
    "        segment_features = np.concatenate((\n",
    "            mean_mfcc, median_mfcc, std_mfcc, skew_mfcc, kurt_mfcc, maximum_mfcc, minimum_mfcc,\n",
    "            [mean_pitch, median_pitch]  # Add pitch statistics to the feature list\n",
    "        ))\n",
    "\n",
    "        mfcc_time_list.append(mfcc_time)\n",
    "        feature_time_list.append(feature_time)\n",
    "        pitch_time_list.append(pitch_time)\n",
    "\n",
    "        feature_list.append(segment_features)\n",
    "\n",
    "        if index == sample_limit * .1:\n",
    "            print(\"10 percent\")\n",
    "        elif index== sample_limit * .2:\n",
    "            print(\"20 percent\")\n",
    "        elif index== sample_limit * .3:\n",
    "            print(\"30 percent\")\n",
    "        elif index== sample_limit * .4:\n",
    "            print(\"40 percent\")\n",
    "        elif index== sample_limit * .5:\n",
    "            print(\"50 percent\")\n",
    "        elif index== sample_limit * .6:\n",
    "            print(\"60 percent\")\n",
    "        elif index== sample_limit * .7:\n",
    "            print(\"70 percent\")\n",
    "        elif index== sample_limit * .8:\n",
    "            print(\"80 percent\")\n",
    "        elif index== sample_limit * .9:\n",
    "            print(\"90 percent\")\n",
    "\n",
    "\n",
    "    # print(sum(mfcc_time_list))\n",
    "    # print(sum(feature_time_list))\n",
    "    # print(sum(pitch_time_list))\n",
    "    return(feature_list)\n",
    "\n",
    "def extract_features_wrapper(segment_dict, save_to):\n",
    "    feature_dict = {}\n",
    "\n",
    "    for key in segment_dict.keys():\n",
    "        extracted_features = extract_features(segment_dict[key]) \n",
    "        feature_dict[key] = extracted_features\n",
    "\n",
    "        with open(f\"../../../data/extracted_features_v2/seperate/features_20_{key}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(extracted_features, file)\n",
    "    \n",
    "    with open(f\"../../../data/extracted_features_v2/{save_to}.pickle\", \"wb\") as file:\n",
    "        pickle.dump(feature_dict, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_format_frequencies(audio_segments, sample_rate=16000):\n",
    "    \n",
    "    format_time_list = []\n",
    "    feature_list = []\n",
    "    sample_limit = 300\n",
    "    for index, segment in enumerate(audio_segments[0:sample_limit]):\n",
    "\n",
    "        format_start_time = time.time()\n",
    "        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=segment, sr=sample_rate))\n",
    "        spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=segment, sr=sample_rate))\n",
    "        spectral_flatness = np.mean(librosa.feature.spectral_flatness(y=segment))\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=segment, sr=sample_rate))\n",
    "        format_time = time.time() - format_start_time\n",
    "        \n",
    "        segment_features = np.array([\n",
    "            spectral_centroid.item() if isinstance(spectral_centroid, np.ndarray) else spectral_centroid,\n",
    "            spectral_bandwidth.item() if isinstance(spectral_bandwidth, np.ndarray) else spectral_bandwidth,\n",
    "            spectral_flatness.item() if isinstance(spectral_flatness, np.ndarray) else spectral_flatness,\n",
    "            spectral_rolloff.item() if isinstance(spectral_rolloff, np.ndarray) else spectral_rolloff\n",
    "        ])\n",
    "\n",
    "        feature_list.append(segment_features)\n",
    "\n",
    "        if index == int(sample_limit * .1):\n",
    "            print(\"10 percent\")\n",
    "        elif index == int(sample_limit * .2):\n",
    "            print(\"20 percent\")\n",
    "        elif index == int(sample_limit * .3):\n",
    "            print(\"30 percent\")\n",
    "        elif index == int(sample_limit * .4):\n",
    "            print(\"40 percent\")\n",
    "        elif index == int(sample_limit * .5):\n",
    "            print(\"50 percent\")\n",
    "        elif index == int(sample_limit * .6):\n",
    "            print(\"60 percent\")\n",
    "        elif index == int(sample_limit * .7):\n",
    "            print(\"70 percent\")\n",
    "        elif index == int(sample_limit * .8):\n",
    "            print(\"80 percent\")\n",
    "        elif index == int(sample_limit * .9):\n",
    "            print(\"90 percent\")\n",
    "\n",
    "        format_time_list.append(format_time)\n",
    "    \n",
    "    print(\"Format extraction time:\", sum(format_time_list))\n",
    "    return feature_list\n",
    "\n",
    "def extract_format_frequencies_wrapper(segment_dict):\n",
    "    feature_dict = {}\n",
    "\n",
    "    for key in segment_dict.keys():\n",
    "        extracted_features = extract_format_frequencies(segment_dict[key]) \n",
    "        feature_dict[key] = extracted_features\n",
    "\n",
    "        with open(f\"../../../data/extracted_features_v2/seperate/features_20_{key}.pickle\", \"wb\") as file:\n",
    "            pickle.dump(extracted_features, file)\n",
    "    \n",
    "    with open(f\"../../../data/extracted_features_v2/format_frequencies.pickle\", \"wb\") as file:\n",
    "        pickle.dump(feature_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lfcc_features(audio_segments, sample_rate=16000):\n",
    "    \n",
    "    lfcc_time_list = []\n",
    "    feature_time_list = []\n",
    "\n",
    "    feature_list = []\n",
    "    sample_limit = 300\n",
    "    for index, segment in enumerate(audio_segments[0:sample_limit]):\n",
    "\n",
    "        lfcc_start_time = time.time()\n",
    "        \n",
    "        # Linear Frequency Cepstral Coefficients (LFCC) extraction\n",
    "        # Compute the linear frequency spectrogram\n",
    "        linear_spectrogram = librosa.stft(segment)\n",
    "        mag, phase = librosa.magphase(linear_spectrogram)\n",
    "        \n",
    "        # Apply log scaling\n",
    "        log_magnitude = np.log1p(mag)\n",
    "        \n",
    "        # Apply Discrete Cosine Transform (DCT) to get LFCC coefficients\n",
    "        lfcc_data = librosa.feature.mfcc(S=log_magnitude, sr=sample_rate, n_mfcc=20)\n",
    "        \n",
    "        lfcc_time = time.time() - lfcc_start_time\n",
    "\n",
    "        feature_start_time = time.time()\n",
    "        # Calculating various statistic measures on the LFCC coefficients\n",
    "        mean_lfcc = np.mean(lfcc_data, axis=1)\n",
    "        median_lfcc = np.median(lfcc_data, axis=1)\n",
    "        std_lfcc = np.std(lfcc_data, axis=1)\n",
    "        skew_lfcc = skew(lfcc_data, axis=1)\n",
    "        kurt_lfcc = kurtosis(lfcc_data, axis=1)\n",
    "        maximum_lfcc = np.amax(lfcc_data, axis=1)\n",
    "        minimum_lfcc = np.amin(lfcc_data, axis=1)\n",
    "        \n",
    "        feature_time = time.time() - feature_start_time\n",
    "\n",
    "        segment_features = np.concatenate((\n",
    "            mean_lfcc, median_lfcc, std_lfcc, skew_lfcc, kurt_lfcc, maximum_lfcc, minimum_lfcc\n",
    "        ))\n",
    "\n",
    "        lfcc_time_list.append(lfcc_time)\n",
    "        feature_time_list.append(feature_time)\n",
    "\n",
    "        feature_list.append(segment_features)\n",
    "\n",
    "        # Progress tracking\n",
    "        if index == sample_limit * .1:\n",
    "            print(\"10 percent\")\n",
    "        elif index == sample_limit * .2:\n",
    "            print(\"20 percent\")\n",
    "        elif index == sample_limit * .3:\n",
    "            print(\"30 percent\")\n",
    "        elif index == sample_limit * .4:\n",
    "            print(\"40 percent\")\n",
    "        elif index == sample_limit * .5:\n",
    "            print(\"50 percent\")\n",
    "        elif index == sample_limit * .6:\n",
    "            print(\"60 percent\")\n",
    "        elif index == sample_limit * .7:\n",
    "            print(\"70 percent\")\n",
    "        elif index == sample_limit * .8:\n",
    "            print(\"80 percent\")\n",
    "        elif index == sample_limit * .9:\n",
    "            print(\"90 percent\")\n",
    "\n",
    "    return feature_list\n",
    "\n",
    "def extract_lfcc_features_wrapper(segment_dict):\n",
    "    feature_dict = {}\n",
    "\n",
    "    for key in segment_dict.keys():\n",
    "        extracted_features = extract_lfcc_features(segment_dict[key]) \n",
    "        feature_dict[key] = extracted_features\n",
    "\n",
    "\n",
    "    with open(f\"../../../data/extracted_features_v2/lfcc_features.pickle\", \"wb\") as file:\n",
    "        pickle.dump(feature_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dictionary = get_file_paths_by_subfolder(r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN AGAIN \n",
    "combine_wav_files(file_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['1069', '19', '201', '250', '254', '26', '27', '289', '298', '311', '32', '3240', '39', '40', '4297', '60', '78', '7800', '83', '87'])\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\1069.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\19.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\201.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\250.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\254.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\26.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\27.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\289.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\298.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\311.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\32.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\3240.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\39.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\40.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\4297.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\60.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\78.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\7800.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\83.wav\n",
      "C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\\87.wav\n"
     ]
    }
   ],
   "source": [
    "audio_paths = get_audio_paths(r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\cleaned_combined\")\n",
    "\n",
    "print(audio_paths.keys())\n",
    "for key in audio_paths.keys():\n",
    "    print(audio_paths[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['1069', '19', '201', '250', '254', '26', '27', '289', '298', '311', '32', '3240', '39', '40', '4297', '60', '78', '7800', '83', '87'])\n"
     ]
    }
   ],
   "source": [
    "segment_dict = segment_audio_wrapper(audio_paths)\n",
    "\n",
    "print(segment_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features_wrapper(segment_dict, \"mfcc_20_no_pitch_10min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_format_frequencies_wrapper(segment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n",
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "90 percent\n"
     ]
    }
   ],
   "source": [
    "extract_lfcc_features_wrapper(segment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 percent\n",
      "20 percent\n",
      "30 percent\n",
      "40 percent\n",
      "50 percent\n",
      "60 percent\n",
      "70 percent\n",
      "80 percent\n",
      "80 percent\n"
     ]
    }
   ],
   "source": [
    "extraced_features = extract_features(segment_dict['26'])\n",
    "\n",
    "with open(f\"../../../data/extracted_features_v2/speaker_26.pickle\", \"wb\") as file:\n",
    "    pickle.dump(extraced_features, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioMed_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
