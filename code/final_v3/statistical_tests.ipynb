{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from scipy.stats import mannwhitneyu, kruskal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_data(file_path):\n",
    "    subject_data = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Regular expression to capture subject identifiers like 1069, 19, 201, etc.\n",
    "    subject_pattern = re.compile(r\"^(\\d+):\")\n",
    "    \n",
    "    current_subject = None\n",
    "    for line in lines:\n",
    "        match = subject_pattern.match(line.strip())\n",
    "        \n",
    "        if match:\n",
    "            current_subject = match.group(1)  # subject ID\n",
    "            subject_data[current_subject] = {}\n",
    "        elif current_subject:\n",
    "            # Extracting the values for accuracy, precision, recall, F1-score, and ROC AUC\n",
    "            if \"accuracy\" in line:\n",
    "                subject_data[current_subject]['accuracy'] = float(line.split(\":\")[1].strip())\n",
    "            elif \"precision\" in line:\n",
    "                subject_data[current_subject]['precision'] = float(line.split(\":\")[1].strip())\n",
    "            elif \"recall\" in line:\n",
    "                subject_data[current_subject]['recall'] = float(line.split(\":\")[1].strip())\n",
    "            elif \"F1-score\" in line:\n",
    "                subject_data[current_subject]['F1-score'] = float(line.split(\":\")[1].strip())\n",
    "            elif \"ROC AUC\" in line:\n",
    "                subject_data[current_subject]['ROC AUC'] = float(line.split(\":\")[1].strip())\n",
    "    \n",
    "    return subject_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform the tests\n",
    "def compare_metrics(file_path_1, file_path_2):\n",
    "    # Extract data from both files\n",
    "    data_1 = extract_subject_data(file_path_1)\n",
    "    data_2 = extract_subject_data(file_path_2)\n",
    "    \n",
    "    # Prepare a dictionary to store comparison results for each metric\n",
    "    comparison_results = {}\n",
    "    \n",
    "    # Compare metrics\n",
    "    for metric in ['accuracy', 'precision', 'recall', 'F1-score', 'ROC AUC']:\n",
    "        # Extract values for the current metric from both data sets\n",
    "        metric_data_1 = [subject_data[metric] for subject_data in data_1.values()]\n",
    "        metric_data_2 = [subject_data[metric] for subject_data in data_2.values()]\n",
    "        \n",
    "        # Mann-Whitney U Test\n",
    "        u_statistic, p_value_mannwhitney = mannwhitneyu(metric_data_1, metric_data_2)\n",
    "        \n",
    "        # Kruskal-Wallis Test\n",
    "        h_statistic, p_value_kruskal = kruskal(metric_data_1, metric_data_2)\n",
    "        \n",
    "        # Store the results in the comparison_results dictionary\n",
    "        comparison_results[metric] = {\n",
    "            'Mann-Whitney U Test': {\n",
    "                'U-statistic': f\"{u_statistic:.3f}\",\n",
    "                'p-value': f\"{p_value_mannwhitney:.3f}\"\n",
    "            },\n",
    "            'Kruskal-Wallis Test': {\n",
    "                'H-statistic': f\"{h_statistic:.3f}\",\n",
    "                'p-value': f\"{p_value_kruskal:.3f}\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return comparison_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: accuracy\n",
      "  Mann-Whitney U Test:\n",
      "    U-statistic = 215.500\n",
      "    p-value = 0.685\n",
      "  Kruskal-Wallis Test:\n",
      "    H-statistic = 0.176\n",
      "    p-value = 0.675\n",
      "Metric: precision\n",
      "  Mann-Whitney U Test:\n",
      "    U-statistic = 224.500\n",
      "    p-value = 0.516\n",
      "  Kruskal-Wallis Test:\n",
      "    H-statistic = 0.439\n",
      "    p-value = 0.507\n",
      "Metric: recall\n",
      "  Mann-Whitney U Test:\n",
      "    U-statistic = 217.500\n",
      "    p-value = 0.645\n",
      "  Kruskal-Wallis Test:\n",
      "    H-statistic = 0.225\n",
      "    p-value = 0.636\n",
      "Metric: F1-score\n",
      "  Mann-Whitney U Test:\n",
      "    U-statistic = 212.500\n",
      "    p-value = 0.745\n",
      "  Kruskal-Wallis Test:\n",
      "    H-statistic = 0.114\n",
      "    p-value = 0.735\n",
      "Metric: ROC AUC\n",
      "  Mann-Whitney U Test:\n",
      "    U-statistic = 223.000\n",
      "    p-value = 0.543\n",
      "  Kruskal-Wallis Test:\n",
      "    H-statistic = 0.387\n",
      "    p-value = 0.534\n"
     ]
    }
   ],
   "source": [
    "# data_1 = \"./metrics/SVM/scaled_rbf_mfcc_20_no_pitch_rand.txt\"\n",
    "# data_2 = \"./metrics/SVM/scaled_rbf_mfcc_20_pitch_rand.txt\"\n",
    "\n",
    "# data_1 = \"./metrics/SVM/rbf_pca_mfcc_20_no_pitch_rand.txt\"\n",
    "# data_2 = \"./metrics/SVM/rbf_pca_mfcc_20_pitch_rand.txt\"\n",
    "\n",
    "# data_1 = \"./metrics/SVM/scaled_rbf_mfcc_20_no_pitch_rand.txt\"\n",
    "# data_2 = \"./metrics/SVM/rbf_pca_mfcc_20_no_pitch_rand.txt\"\n",
    "\n",
    "data_1 = \"./metrics/HMM/diag_5_mfcc_20_no_pitch_rand.txt\"\n",
    "data_2 = \"./metrics/HMM/diag_5_pca_mfcc_20_no_pitch_rand.txt\"\n",
    "\n",
    "# data_2 = \"./metrics/HMM/diag_5_mfcc_20_pitch_rand.txt\"\n",
    "\n",
    "results = compare_metrics(data_1, data_2)\n",
    "\n",
    "for metric, result in results.items():\n",
    "    print(f\"Metric: {metric}\")\n",
    "    for test, values in result.items():\n",
    "        print(f\"  {test}:\")\n",
    "        # Access 'U-statistic' for Mann-Whitney U Test, and 'H-statistic' for Kruskal-Wallis Test\n",
    "        statistic_key = 'U-statistic' if 'Mann-Whitney' in test else 'H-statistic'\n",
    "        print(f\"    {statistic_key} = {values[statistic_key]}\")\n",
    "        print(f\"    p-value = {values['p-value']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioMed_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
