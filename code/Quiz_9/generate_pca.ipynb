{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reader: 1069 | # samples 300\n",
      "reader: 19 | # samples 300\n",
      "reader: 201 | # samples 300\n",
      "reader: 250 | # samples 300\n",
      "reader: 254 | # samples 300\n",
      "reader: 26 | # samples 300\n",
      "reader: 27 | # samples 300\n",
      "reader: 289 | # samples 300\n",
      "reader: 298 | # samples 300\n",
      "reader: 311 | # samples 300\n",
      "reader: 32 | # samples 300\n",
      "reader: 3240 | # samples 300\n",
      "reader: 39 | # samples 300\n",
      "reader: 40 | # samples 300\n",
      "reader: 4297 | # samples 300\n",
      "reader: 60 | # samples 300\n",
      "reader: 78 | # samples 300\n",
      "reader: 7800 | # samples 300\n",
      "reader: 83 | # samples 300\n",
      "reader: 87 | # samples 300\n"
     ]
    }
   ],
   "source": [
    "features = \"mfcc_20_no_pitch_rand\"\n",
    "\n",
    "with open(f\"../../data/extracted_features_v2/{features}.pickle\", \"rb\") as file:\n",
    "   mfcc_stats_dict = pickle.load(file)\n",
    "\n",
    "for reader in mfcc_stats_dict.keys():\n",
    "    print(f\"reader: {reader} | # samples {len(mfcc_stats_dict[reader])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(data, n_components=None):\n",
    "    \"\"\"\n",
    "    Applies PCA to a 2D dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - data (numpy.ndarray): 2D array with shape (n_instances, n_features).\n",
    "    - n_components (int, float, or None): Number of principal components to keep.\n",
    "        If None, all components are kept.\n",
    "        If float between 0 and 1, selects the number of components such that \n",
    "        the amount of variance that needs to be explained is greater than n_components.\n",
    "\n",
    "    Returns:\n",
    "    - transformed_data (numpy.ndarray): Data projected onto principal components.\n",
    "    - explained_variance_ratio (numpy.ndarray): Variance explained by each component.\n",
    "    - pca_model (PCA): The PCA model (useful for future transformations).\n",
    "    \"\"\"\n",
    "    if not isinstance(data, np.ndarray) or len(data.shape) != 2:\n",
    "        raise ValueError(\"Input data must be a 2D numpy array.\")\n",
    "\n",
    "    # Initialize the PCA model\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "    # Fit the PCA model to the data and transform it\n",
    "    transformed_data = pca.fit_transform(data)\n",
    "\n",
    "    # Return the transformed data, explained variance ratio, and the PCA model\n",
    "    return transformed_data, pca.explained_variance_ratio_, pca\n",
    "\n",
    "def apply_pca_wrapper(data_dict, n_components=None):\n",
    "    \"\"\"\n",
    "    Applies PCA to each 2D array in a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - data_dict (dict): A dictionary where values are 2D lists or numpy arrays.\n",
    "        Each 2D array should have shape (n_instances, n_features).\n",
    "    - n_components (int, float, or None): Number of principal components to keep.\n",
    "        See `apply_pca` for details.\n",
    "\n",
    "    Returns:\n",
    "    - transformed_dict (dict): A new dictionary with the same keys as `data_dict`,\n",
    "        where values are the PCA-transformed 2D arrays.\n",
    "    - pca_models (dict): A dictionary of PCA models for each key.\n",
    "    \"\"\"\n",
    "    transformed_dict = {}\n",
    "    pca_models = {}\n",
    "\n",
    "    for key, data in data_dict.items():\n",
    "        # Convert data to a numpy array if it isn't one already\n",
    "        data = np.array(data)\n",
    "        \n",
    "        # Check if data is valid\n",
    "        if len(data.shape) != 2:\n",
    "            raise ValueError(f\"Data for key '{key}' is not 2D.\")\n",
    "\n",
    "        # Apply PCA to the current data\n",
    "        transformed_data, _, pca_model = apply_pca(data, n_components)\n",
    "\n",
    "        # Store the transformed data and PCA model\n",
    "        transformed_dict[key] = transformed_data\n",
    "        pca_models[key] = pca_model\n",
    "\n",
    "    return transformed_dict, pca_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 1069 shape: (300, 140)\n",
      "key: 19 shape: (300, 140)\n",
      "key: 201 shape: (300, 140)\n",
      "key: 250 shape: (300, 140)\n",
      "key: 254 shape: (300, 140)\n",
      "key: 26 shape: (300, 140)\n",
      "key: 27 shape: (300, 140)\n",
      "key: 289 shape: (300, 140)\n",
      "key: 298 shape: (300, 140)\n",
      "key: 311 shape: (300, 140)\n",
      "key: 32 shape: (300, 140)\n",
      "key: 3240 shape: (300, 140)\n",
      "key: 39 shape: (300, 140)\n",
      "key: 40 shape: (300, 140)\n",
      "key: 4297 shape: (300, 140)\n",
      "key: 60 shape: (300, 140)\n",
      "key: 78 shape: (300, 140)\n",
      "key: 7800 shape: (300, 140)\n",
      "key: 83 shape: (300, 140)\n",
      "key: 87 shape: (300, 140)\n"
     ]
    }
   ],
   "source": [
    "pca_dictionary, pca_models = apply_pca_wrapper(mfcc_stats_dict)\n",
    "\n",
    "for key in pca_dictionary.keys():\n",
    "    print(f\"key: {key} shape: {pca_dictionary[key].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../../data/extracted_features_v2/pca_{features}.pickle\", \"wb\") as file:\n",
    "    pickle.dump(pca_dictionary, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioMed_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
