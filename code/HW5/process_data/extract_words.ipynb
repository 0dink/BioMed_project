{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pocketsphinx import AudioFile, get_model_path, Decoder\n",
    "from pydub import AudioSegment\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word_audio(input_wav, output_wav, target_word=\"that\", extra_time=0):\n",
    "    # Set up paths for the models\n",
    "    model_path = get_model_path()\n",
    "    \n",
    "    # Create a list to hold the start and end times of the target word\n",
    "    word_times = []\n",
    "\n",
    "    # Create a decoder with the appropriate configuration\n",
    "    config = {\n",
    "        'verbose': False,\n",
    "        'hmm': os.path.join(model_path, 'en-us'),  # Path to the acoustic model\n",
    "        'lm': os.path.join(model_path, 'en-us.lm.bin'),  # Path to the language model\n",
    "        'dict': os.path.join(model_path, 'cmudict-en-us.dict'),  # Path to the dictionary\n",
    "        'frate': 100,\n",
    "        'samprate': 16000\n",
    "    }\n",
    "    \n",
    "    # Initialize the decoder\n",
    "    decoder = Decoder(config)\n",
    "\n",
    "    # Start decoding the audio file\n",
    "    decoder.start_utt()\n",
    "    \n",
    "    # Read the audio file in binary mode and process it\n",
    "    with open(input_wav, 'rb') as audio_file:\n",
    "        while True:\n",
    "            buf = audio_file.read(1024)\n",
    "            if not buf:\n",
    "                break\n",
    "            decoder.process_raw(buf, False, False)\n",
    "\n",
    "    decoder.end_utt()\n",
    "\n",
    "    # Check for the target word in the recognized segments\n",
    "    recognized_words = []\n",
    "    for seg in decoder.seg():\n",
    "        word = seg.word.split('(')[0]  # Get the word before the hypothesis index\n",
    "        recognized_words.append(word)  # Collect all recognized words\n",
    "        # Check if the segment matches the target word\n",
    "        if word.lower() == target_word.lower():\n",
    "            # Append start and end times (in milliseconds)\n",
    "            start_time = int(seg.start_frame * (1000 / 100))  # Assuming 100 frames per second\n",
    "            end_time = int(seg.end_frame * (1000 / 100))      # Adjust frame rate if necessary\n",
    "            # Adjust start and end times for extra recording\n",
    "            adjusted_start = max(0, start_time - extra_time)  # One second before\n",
    "            adjusted_end = end_time + extra_time               # One second after\n",
    "            word_times.append((adjusted_start, adjusted_end))\n",
    "\n",
    "    # Print recognized words\n",
    "    print(\"Recognized words:\", ' '.join(recognized_words))\n",
    "\n",
    "    # Check if the word was found\n",
    "    if not word_times:\n",
    "        print(f\"The word '{target_word}' was not found in the audio {input_wav}.\")\n",
    "        return\n",
    "\n",
    "    # Load the original audio file\n",
    "    original_audio = AudioSegment.from_wav(input_wav)\n",
    "\n",
    "    # Extract segments for each occurrence of the target word\n",
    "    for i, (start, end) in enumerate(word_times):\n",
    "        # Ensure the start and end times are within the audio length\n",
    "        start = max(0, start)\n",
    "        end = min(len(original_audio), end)\n",
    "        \n",
    "        # Extract the audio segment\n",
    "        word_audio = original_audio[start:end]\n",
    "        \n",
    "        # Save the extracted segment using the original sample rate\n",
    "        name_without_extension = os.path.splitext(output_wav)[0]\n",
    "        output_file = f\"{name_without_extension}_{i + 1}.wav\"\n",
    "        word_audio.export(output_file, format=\"wav\")\n",
    "        print(f\"Extracted '{target_word}' to '{output_file}' from {start}ms to {end}ms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_occurrences(file_paths):\n",
    "    word_count = defaultdict(lambda: [0, set()])  # Default dictionary to hold (count, set of identifiers)\n",
    "    \n",
    "    # Read each file and count words\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                identifier, text = line.split(' ', 1)\n",
    "                words = text.split()\n",
    "                \n",
    "                for word in words:\n",
    "                    # Normalize words to lowercase for consistent counting\n",
    "                    normalized_word = word.lower()\n",
    "                    word_count[normalized_word][0] += 1  # Increment word count\n",
    "                    word_count[normalized_word][1].add(identifier)  # Add identifier\n",
    "\n",
    "    # Create a sorted list from the dictionary\n",
    "    sorted_word_counts = [\n",
    "        (count_info[0], word, list(count_info[1])) \n",
    "        for word, count_info in word_count.items()\n",
    "    ]\n",
    "    sorted_word_counts.sort(key=lambda x: x[0], reverse=True)  # Sort by count (descending)\n",
    "\n",
    "    return sorted_word_counts\n",
    "\n",
    "def count_speaker_occurrences(identifiers):\n",
    "    speaker_count = defaultdict(int)  # Default dictionary to hold counts of each speaker\n",
    "\n",
    "    # Count occurrences of each speaker\n",
    "    for identifier in identifiers:\n",
    "        speaker_number = identifier.split('-')[0]  # Extract speaker number\n",
    "        speaker_count[speaker_number] += 1  # Increment the count for the speaker\n",
    "\n",
    "    # Convert to a regular dictionary for better readability\n",
    "    return dict(speaker_count)\n",
    "\n",
    "def generate_path(filename, path_prefix):\n",
    "    reader, chapter, trial = filename.split('-')\n",
    "    return f\"{path_prefix}/{reader}/{chapter}/{reader}-{chapter}-{trial}.wav\"\n",
    "\n",
    "\n",
    "def word_extraction_wrapper(files_to_search, save_to_path, word, time_padding):\n",
    "    for file in files_to_search:\n",
    "        _, _, _, _, _, _, _, speaker, chapter, file_name = file.split('/')\n",
    "\n",
    "        save_to = f\"{save_to_path}/{word}_no_extra_time/{speaker}/{file_name}\"\n",
    "        extract_word_audio(file, save_to, word, time_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 'her', ['19-198-0035', '19-198-0028', '19-198-0031', '19-198-0034', '19-198-0032', '19-198-0015', '19-198-0012', '19-198-0013', '19-198-0037', '19-198-0014', '19-198-0029', '19-198-0020', '19-198-0016', '19-198-0022', '19-198-0019', '19-198-0009', '19-198-0005', '19-198-0021', '19-198-0018', '19-198-0004', '19-198-0007', '19-198-0030', '19-198-0011', '19-198-0006'])\n",
      "(48, 'and', ['19-198-0035', '19-198-0028', '19-198-0034', '19-198-0032', '19-198-0015', '19-198-0003', '19-198-0012', '19-198-0027', '19-198-0013', '19-198-0014', '19-198-0029', '19-198-0020', '19-198-0016', '19-198-0022', '19-198-0019', '19-198-0009', '19-198-0036', '19-198-0005', '19-198-0001', '19-198-0025', '19-198-0017', '19-198-0021', '19-198-0018', '19-198-0023', '19-198-0007', '19-198-0026', '19-198-0011', '19-198-0006'])\n",
      "(44, 'the', ['19-198-0002', '19-198-0035', '19-198-0031', '19-198-0034', '19-198-0003', '19-198-0027', '19-198-0033', '19-198-0013', '19-198-0014', '19-198-0020', '19-198-0010', '19-198-0019', '19-198-0036', '19-198-0005', '19-198-0001', '19-198-0025', '19-198-0017', '19-198-0021', '19-198-0023', '19-198-0007', '19-198-0026', '19-198-0030', '19-198-0011', '19-198-0029'])\n",
      "(37, 'she', ['19-198-0028', '19-198-0031', '19-198-0015', '19-198-0012', '19-198-0013', '19-198-0037', '19-198-0014', '19-198-0029', '19-198-0020', '19-198-0016', '19-198-0010', '19-198-0019', '19-198-0009', '19-198-0024', '19-198-0018', '19-198-0026', '19-198-0030', '19-198-0008', '19-198-0011', '19-198-0006'])\n",
      "(34, 'a', ['19-198-0035', '19-198-0028', '19-198-0034', '19-198-0015', '19-198-0027', '19-198-0020', '19-198-0016', '19-198-0010', '19-198-0036', '19-198-0005', '19-198-0024', '19-198-0001', '19-198-0025', '19-198-0021', '19-198-0026', '19-198-0030', '19-198-0006', '19-198-0008', '19-198-0033', '19-198-0029'])\n",
      "(32, 'was', ['19-198-0028', '19-198-0034', '19-198-0032', '19-198-0003', '19-198-0012', '19-198-0033', '19-198-0013', '19-198-0014', '19-198-0016', '19-198-0022', '19-198-0009', '19-198-0036', '19-198-0005', '19-198-0024', '19-198-0001', '19-198-0017', '19-198-0021', '19-198-0030', '19-198-0011', '19-198-0006'])\n",
      "(32, 'to', ['19-198-0035', '19-198-0031', '19-198-0015', '19-198-0003', '19-198-0013', '19-198-0037', '19-198-0014', '19-198-0020', '19-198-0022', '19-198-0010', '19-198-0019', '19-198-0036', '19-198-0024', '19-198-0001', '19-198-0025', '19-198-0021', '19-198-0018', '19-198-0023', '19-198-0004', '19-198-0007', '19-198-0026', '19-198-0030', '19-198-0011', '19-198-0029'])\n",
      "(31, 'of', ['19-198-0002', '19-198-0035', '19-198-0031', '19-198-0034', '19-198-0015', '19-198-0014', '19-198-0016', '19-198-0010', '19-198-0019', '19-198-0009', '19-198-0036', '19-198-0005', '19-198-0001', '19-198-0017', '19-198-0023', '19-198-0007', '19-198-0026', '19-198-0030', '19-198-0006', '19-198-0011', '19-198-0029'])\n",
      "(22, 'in', ['19-198-0007', '19-198-0036', '19-198-0027', '19-198-0033', '19-198-0030', '19-198-0024', '19-198-0013', '19-198-0035', '19-198-0014', '19-198-0001', '19-198-0028', '19-198-0015', '19-198-0016', '19-198-0017', '19-198-0021', '19-198-0004', '19-198-0003'])\n",
      "(20, 'for', ['19-198-0007', '19-198-0012', '19-198-0036', '19-198-0033', '19-198-0024', '19-198-0014', '19-198-0001', '19-198-0028', '19-198-0031', '19-198-0016', '19-198-0018', '19-198-0022', '19-198-0023', '19-198-0010', '19-198-0019', '19-198-0011', '19-198-0009'])\n",
      "(15, 'not', ['19-198-0012', '19-198-0033', '19-198-0030', '19-198-0013', '19-198-0028', '19-198-0031', '19-198-0016', '19-198-0022', '19-198-0034', '19-198-0010', '19-198-0015', '19-198-0009'])\n",
      "(13, 'as', ['19-198-0007', '19-198-0012', '19-198-0026', '19-198-0027', '19-198-0002', '19-198-0024', '19-198-0014', '19-198-0017', '19-198-0019'])\n",
      "(13, 'that', ['19-198-0026', '19-198-0027', '19-198-0036', '19-198-0030', '19-198-0013', '19-198-0025', '19-198-0023', '19-198-0022', '19-198-0003'])\n",
      "(13, 'had', ['19-198-0007', '19-198-0030', '19-198-0024', '19-198-0031', '19-198-0022', '19-198-0008', '19-198-0010', '19-198-0019', '19-198-0004', '19-198-0034', '19-198-0006'])\n",
      "(13, 'at', ['19-198-0011', '19-198-0024', '19-198-0028', '19-198-0031', '19-198-0016', '19-198-0017', '19-198-0023', '19-198-0034', '19-198-0015'])\n",
      "(11, 'it', ['19-198-0013', '19-198-0014', '19-198-0001', '19-198-0025', '19-198-0003', '19-198-0015', '19-198-0022', '19-198-0011'])\n",
      "(10, 'no', ['19-198-0030', '19-198-0013', '19-198-0031', '19-198-0023', '19-198-0034', '19-198-0010', '19-198-0004', '19-198-0033', '19-198-0029'])\n",
      "(10, 'were', ['19-198-0007', '19-198-0012', '19-198-0005', '19-198-0020', '19-198-0017', '19-198-0018', '19-198-0022', '19-198-0023', '19-198-0011'])\n",
      "(8, 'catherine', ['19-198-0007', '19-198-0013', '19-198-0014', '19-198-0020', '19-198-0017', '19-198-0022', '19-198-0004', '19-198-0006'])\n",
      "(8, 'all', ['19-198-0005', '19-198-0024', '19-198-0013', '19-198-0016', '19-198-0023', '19-198-0011', '19-198-0009'])\n",
      "(8, 'very', ['19-198-0007', '19-198-0005', '19-198-0014', '19-198-0021', '19-198-0022', '19-198-0032', '19-198-0029'])\n",
      "(8, 'could', ['19-198-0012', '19-198-0013', '19-198-0028', '19-198-0016', '19-198-0023', '19-198-0032', '19-198-0015', '19-198-0029'])\n",
      "(7, 'one', ['19-198-0034', '19-198-0032', '19-198-0004', '19-198-0033'])\n",
      "(7, 'be', ['19-198-0030', '19-198-0035', '19-198-0021', '19-198-0023', '19-198-0004', '19-198-0033'])\n",
      "(7, 'but', ['19-198-0007', '19-198-0024', '19-198-0035', '19-198-0021', '19-198-0010', '19-198-0032', '19-198-0033'])\n",
      "(7, 'so', ['19-198-0011', '19-198-0024', '19-198-0028', '19-198-0021', '19-198-0017', '19-198-0015', '19-198-0009'])\n",
      "(7, 'on', ['19-198-0028', '19-198-0025', '19-198-0022', '19-198-0019', '19-198-0015', '19-198-0029'])\n",
      "(6, 'is', ['19-198-0002', '19-198-0035', '19-198-0020', '19-198-0025', '19-198-0006'])\n",
      "(6, 'who', ['19-198-0036', '19-198-0022', '19-198-0034', '19-198-0032', '19-198-0004', '19-198-0015'])\n",
      "(6, 'mother', ['19-198-0005', '19-198-0013', '19-198-0014', '19-198-0016', '19-198-0019', '19-198-0006'])\n",
      "(6, 'with', ['19-198-0024', '19-198-0037', '19-198-0029', '19-198-0016', '19-198-0006'])\n",
      "(6, 'from', ['19-198-0026', '19-198-0024', '19-198-0025', '19-198-0021', '19-198-0023', '19-198-0011'])\n",
      "(5, 'even', ['19-198-0012', '19-198-0030', '19-198-0001', '19-198-0032', '19-198-0033'])\n",
      "(5, 'have', ['19-198-0004', '19-198-0003', '19-198-0002'])\n",
      "(5, 'any', ['19-198-0007', '19-198-0002', '19-198-0024', '19-198-0014', '19-198-0032'])\n",
      "(5, 'which', ['19-198-0027', '19-198-0002', '19-198-0024', '19-198-0020', '19-198-0011'])\n",
      "(5, 'years', ['19-198-0007', '19-198-0002', '19-198-0003', '19-198-0016', '19-198-0015'])\n",
      "(5, 'many', ['19-198-0007', '19-198-0014', '19-198-0028', '19-198-0025', '19-198-0003'])\n",
      "(5, 'more', ['19-198-0018', '19-198-0010', '19-198-0003', '19-198-0006'])\n",
      "(5, 'morland', ['19-198-0036', '19-198-0017', '19-198-0021', '19-198-0004', '19-198-0015'])\n",
      "(5, 'or', ['19-198-0012', '19-198-0005', '19-198-0023', '19-198-0010', '19-198-0015'])\n",
      "(5, 'good', ['19-198-0020', '19-198-0036', '19-198-0021', '19-198-0006'])\n",
      "(5, 'there', ['19-198-0007', '19-198-0031', '19-198-0034', '19-198-0033', '19-198-0029'])\n",
      "(5, 'by', ['19-198-0013', '19-198-0016', '19-198-0018', '19-198-0022', '19-198-0029'])\n",
      "(4, 'little', ['19-198-0007', '19-198-0021', '19-198-0029', '19-198-0001'])\n",
      "(4, 'other', ['19-198-0029', '19-198-0007', '19-198-0002', '19-198-0028'])\n",
      "(4, 'are', ['19-198-0024', '19-198-0007', '19-198-0026', '19-198-0003'])\n",
      "(4, 'books', ['19-198-0024', '19-198-0003', '19-198-0023'])\n",
      "(4, 'father', ['19-198-0034', '19-198-0019', '19-198-0005'])\n",
      "(4, 'without', ['19-198-0032', '19-198-0005'])\n",
      "(4, 'woman', ['19-198-0027', '19-198-0021', '19-198-0036', '19-198-0006'])\n",
      "(4, 'them', ['19-198-0029', '19-198-0037', '19-198-0023'])\n",
      "(4, 'their', ['19-198-0024', '19-198-0034', '19-198-0033'])\n",
      "(4, 'young', ['19-198-0034', '19-198-0025', '19-198-0035', '19-198-0027'])\n",
      "(3, 'three', ['19-198-0013', '19-198-0006', '19-198-0001'])\n",
      "(3, 'than', ['19-198-0013', '19-198-0021', '19-198-0002'])\n",
      "(3, 'those', ['19-198-0024', '19-198-0011', '19-198-0002'])\n",
      "(3, 'born', ['19-198-0025', '19-198-0004', '19-198-0006'])\n",
      "(3, 'heroine', ['19-198-0024', '19-198-0004', '19-198-0035'])\n",
      "(3, 'own', ['19-198-0029', '19-198-0031', '19-198-0005'])\n",
      "(3, 'plain', ['19-198-0007', '19-198-0006'])\n",
      "(3, 'what', ['19-198-0032', '19-198-0016', '19-198-0006'])\n",
      "(3, 'they', ['19-198-0007', '19-198-0021', '19-198-0023'])\n",
      "(3, 'fond', ['19-198-0036', '19-198-0014', '19-198-0009'])\n",
      "(3, 'heroic', ['19-198-0031', '19-198-0010', '19-198-0022'])\n",
      "(3, 'if', ['19-198-0033', '19-198-0011', '19-198-0036'])\n",
      "(3, 'always', ['19-198-0013', '19-198-0027', '19-198-0011'])\n",
      "(3, 'such', ['19-198-0024', '19-198-0017', '19-198-0011'])\n",
      "(3, 'did', ['19-198-0031', '19-198-0013', '19-198-0015'])\n",
      "(3, 'like', ['19-198-0014', '19-198-0023', '19-198-0028'])\n",
      "(3, 'old', ['19-198-0015', '19-198-0016', '19-198-0014'])\n",
      "(3, 'strange', ['19-198-0016', '19-198-0033'])\n",
      "(3, 'nothing', ['19-198-0017', '19-198-0023', '19-198-0022'])\n",
      "(3, 'gained', ['19-198-0023', '19-198-0026', '19-198-0018'])\n",
      "(3, 'about', ['19-198-0036', '19-198-0023', '19-198-0022'])\n",
      "(3, 'read', ['19-198-0024', '19-198-0029'])\n",
      "(3, 'must', ['19-198-0024', '19-198-0037', '19-198-0035'])\n",
      "(3, 'having', ['19-198-0032'])\n",
      "(2, 'this', ['19-198-0033', '19-198-0001'])\n",
      "(2, 'work', ['19-198-0002', '19-198-0001'])\n",
      "(2, 'finished', ['19-198-0003', '19-198-0001'])\n",
      "(2, 'year', ['19-198-0015', '19-198-0001'])\n",
      "(2, 'public', ['19-198-0003', '19-198-0002'])\n",
      "(2, 'upon', ['19-198-0027', '19-198-0002'])\n",
      "(2, 'thirteen', ['19-198-0003', '19-198-0002'])\n",
      "(2, 'bear', ['19-198-0015', '19-198-0003'])\n",
      "(2, 'mind', ['19-198-0003', '19-198-0009'])\n",
      "(2, 'since', ['19-198-0003'])\n",
      "(2, 'ever', ['19-198-0004', '19-198-0021'])\n",
      "(2, 'seen', ['19-198-0032', '19-198-0004'])\n",
      "(2, 'infancy', ['19-198-0010', '19-198-0004'])\n",
      "(2, 'an', ['19-198-0019', '19-198-0004'])\n",
      "(2, 'life', ['19-198-0007', '19-198-0004'])\n",
      "(2, 'character', ['19-198-0016', '19-198-0005'])\n",
      "(2, 'person', ['19-198-0009', '19-198-0005'])\n",
      "(2, 'being', ['19-198-0015', '19-198-0005'])\n",
      "(2, 'poor', ['19-198-0027', '19-198-0005'])\n",
      "(2, 'man', ['19-198-0034', '19-198-0005'])\n",
      "(2, 'useful', ['19-198-0023', '19-198-0006'])\n",
      "(2, 'remarkable', ['19-198-0016', '19-198-0006'])\n",
      "(2, 'constitution', ['19-198-0036', '19-198-0006'])\n",
      "(2, 'before', ['19-198-0012', '19-198-0006'])\n",
      "(2, 'where', ['19-198-0007', '19-198-0036'])\n",
      "(2, 'enough', ['19-198-0007', '19-198-0030'])\n",
      "(2, 'morlands', ['19-198-0007', '19-198-0036'])\n",
      "(2, 'figure', ['19-198-0008', '19-198-0018'])\n",
      "(2, 'hair', ['19-198-0018', '19-198-0009'])\n",
      "(2, 'strong', ['19-198-0026', '19-198-0009'])\n",
      "(2, 'features', ['19-198-0018', '19-198-0009'])\n",
      "(2, 'much', ['19-198-0021', '19-198-0009'])\n",
      "(2, 'seemed', ['19-198-0029', '19-198-0009'])\n",
      "(2, 'cricket', ['19-198-0009', '19-198-0022'])\n",
      "(2, 'indeed', ['19-198-0010', '19-198-0033'])\n",
      "(2, 'pleasure', ['19-198-0019', '19-198-0011'])\n",
      "(2, 'least', ['19-198-0011', '19-198-0023'])\n",
      "(2, 'quite', ['19-198-0020', '19-198-0012'])\n",
      "(2, 'never', ['19-198-0024', '19-198-0012'])\n",
      "(2, 'learn', ['19-198-0012', '19-198-0014'])\n",
      "(2, 'sometimes', ['19-198-0012', '19-198-0019'])\n",
      "(2, 'then', ['19-198-0020', '19-198-0012'])\n",
      "(2, 'stupid', ['19-198-0012', '19-198-0013'])\n",
      "(2, 'teaching', ['19-198-0013', '19-198-0021'])\n",
      "(2, 'learnt', ['19-198-0015', '19-198-0014'])\n",
      "(2, 'girl', ['19-198-0020', '19-198-0014'])\n",
      "(2, 'wished', ['19-198-0021', '19-198-0014'])\n",
      "(2, 'should', ['19-198-0014', '19-198-0022'])\n",
      "(2, 'began', ['19-198-0015', '19-198-0018'])\n",
      "(2, 'missus', ['19-198-0021', '19-198-0015'])\n",
      "(2, 'daughters', ['19-198-0015', '19-198-0022'])\n",
      "(2, 'ten', ['19-198-0016', '19-198-0017'])\n",
      "(2, 'well', ['19-198-0017', '19-198-0028'])\n",
      "(2, 'fifteen', ['19-198-0024', '19-198-0017'])\n",
      "(2, 'love', ['19-198-0019', '19-198-0027'])\n",
      "(2, 'way', ['19-198-0019', '19-198-0035'])\n",
      "(2, 'grew', ['19-198-0019'])\n",
      "(2, 'now', ['19-198-0020', '19-198-0019'])\n",
      "(2, 'improvement', ['19-198-0019', '19-198-0028'])\n",
      "(2, 'almost', ['19-198-0020'])\n",
      "(2, 'pretty', ['19-198-0020'])\n",
      "(2, 'how', ['19-198-0020', '19-198-0025'])\n",
      "(2, 'children', ['19-198-0034', '19-198-0021'])\n",
      "(2, 'age', ['19-198-0031', '19-198-0023'])\n",
      "(2, 'information', ['19-198-0026', '19-198-0023'])\n",
      "(2, 'provided', ['19-198-0023'])\n",
      "(2, 'seventeen', ['19-198-0024', '19-198-0031'])\n",
      "(2, 'air', ['19-198-0025', '19-198-0026'])\n",
      "(2, 'great', ['19-198-0026', '19-198-0027'])\n",
      "(2, 'when', ['19-198-0035', '19-198-0027'])\n",
      "(2, 'though', ['19-198-0029', '19-198-0028'])\n",
      "(2, 'lady', ['19-198-0035', '19-198-0036'])\n",
      "(1, 'northanger', ['19-198-0000'])\n",
      "(1, 'abbey', ['19-198-0000'])\n",
      "(1, 'eighteen', ['19-198-0001'])\n",
      "(1, 'o', ['19-198-0001'])\n",
      "(1, 'intended', ['19-198-0001'])\n",
      "(1, 'immediate', ['19-198-0001'])\n",
      "(1, 'publication', ['19-198-0001'])\n",
      "(1, 'disposed', ['19-198-0001'])\n",
      "(1, 'bookseller', ['19-198-0001'])\n",
      "(1, 'advertised', ['19-198-0001'])\n",
      "(1, 'neither', ['19-198-0002'])\n",
      "(1, 'author', ['19-198-0002'])\n",
      "(1, 'nor', ['19-198-0002'])\n",
      "(1, 'concern', ['19-198-0002'])\n",
      "(1, 'some', ['19-198-0002'])\n",
      "(1, 'observation', ['19-198-0002'])\n",
      "(1, 'necessary', ['19-198-0002'])\n",
      "(1, 'parts', ['19-198-0002'])\n",
      "(1, 'made', ['19-198-0002'])\n",
      "(1, 'comparatively', ['19-198-0002'])\n",
      "(1, 'obsolete', ['19-198-0002'])\n",
      "(1, 'entreated', ['19-198-0003'])\n",
      "(1, 'passed', ['19-198-0003'])\n",
      "(1, 'begun', ['19-198-0003'])\n",
      "(1, 'during', ['19-198-0003'])\n",
      "(1, 'period', ['19-198-0003'])\n",
      "(1, 'places', ['19-198-0003'])\n",
      "(1, 'manners', ['19-198-0003'])\n",
      "(1, 'opinions', ['19-198-0003'])\n",
      "(1, 'undergone', ['19-198-0003'])\n",
      "(1, 'considerable', ['19-198-0003'])\n",
      "(1, 'changes', ['19-198-0003'])\n",
      "(1, 'chapter', ['19-198-0004'])\n",
      "(1, 'would', ['19-198-0004'])\n",
      "(1, 'supposed', ['19-198-0004'])\n",
      "(1, 'situation', ['19-198-0004'])\n",
      "(1, 'disposition', ['19-198-0005'])\n",
      "(1, 'equally', ['19-198-0005'])\n",
      "(1, 'against', ['19-198-0005'])\n",
      "(1, 'clergyman', ['19-198-0005'])\n",
      "(1, 'neglected', ['19-198-0005'])\n",
      "(1, 'respectable', ['19-198-0005'])\n",
      "(1, 'sense', ['19-198-0006'])\n",
      "(1, 'temper', ['19-198-0006'])\n",
      "(1, 'sons', ['19-198-0006'])\n",
      "(1, 'heads', ['19-198-0007'])\n",
      "(1, 'arms', ['19-198-0007'])\n",
      "(1, 'legs', ['19-198-0007'])\n",
      "(1, 'number', ['19-198-0007'])\n",
      "(1, 'right', ['19-198-0007'])\n",
      "(1, 'word', ['19-198-0007'])\n",
      "(1, 'general', ['19-198-0007'])\n",
      "(1, 'thin', ['19-198-0008'])\n",
      "(1, 'awkward', ['19-198-0008'])\n",
      "(1, 'dark', ['19-198-0009'])\n",
      "(1, 'lank', ['19-198-0009'])\n",
      "(1, 'less', ['19-198-0009'])\n",
      "(1, 'unpropitious', ['19-198-0009'])\n",
      "(1, 'heroism', ['19-198-0009'])\n",
      "(1, \"boy's\", ['19-198-0009'])\n",
      "(1, 'plays', ['19-198-0009'])\n",
      "(1, 'greatly', ['19-198-0009'])\n",
      "(1, 'preferred', ['19-198-0009'])\n",
      "(1, 'merely', ['19-198-0010'])\n",
      "(1, 'dolls', ['19-198-0010'])\n",
      "(1, 'enjoyments', ['19-198-0010'])\n",
      "(1, 'nursing', ['19-198-0010'])\n",
      "(1, 'dormouse', ['19-198-0010'])\n",
      "(1, 'feeding', ['19-198-0010'])\n",
      "(1, 'canary', ['19-198-0010'])\n",
      "(1, 'bird', ['19-198-0010'])\n",
      "(1, 'watering', ['19-198-0010'])\n",
      "(1, 'rose', ['19-198-0010'])\n",
      "(1, 'bush', ['19-198-0010'])\n",
      "(1, 'taste', ['19-198-0010'])\n",
      "(1, 'garden', ['19-198-0010'])\n",
      "(1, 'gathered', ['19-198-0011'])\n",
      "(1, 'flowers', ['19-198-0011'])\n",
      "(1, 'chiefly', ['19-198-0011'])\n",
      "(1, 'mischief', ['19-198-0011'])\n",
      "(1, 'conjectured', ['19-198-0011'])\n",
      "(1, 'preferring', ['19-198-0011'])\n",
      "(1, 'forbidden', ['19-198-0011'])\n",
      "(1, 'take', ['19-198-0011'])\n",
      "(1, 'propensities', ['19-198-0011'])\n",
      "(1, 'abilities', ['19-198-0012'])\n",
      "(1, 'extraordinary', ['19-198-0012'])\n",
      "(1, 'understand', ['19-198-0012'])\n",
      "(1, 'anything', ['19-198-0012'])\n",
      "(1, 'taught', ['19-198-0012'])\n",
      "(1, 'often', ['19-198-0012'])\n",
      "(1, 'inattentive', ['19-198-0012'])\n",
      "(1, 'occasionally', ['19-198-0012'])\n",
      "(1, 'months', ['19-198-0013'])\n",
      "(1, 'only', ['19-198-0013'])\n",
      "(1, 'repeat', ['19-198-0013'])\n",
      "(1, \"beggar's\", ['19-198-0013'])\n",
      "(1, 'petition', ['19-198-0013'])\n",
      "(1, 'after', ['19-198-0013'])\n",
      "(1, 'next', ['19-198-0013'])\n",
      "(1, 'sister', ['19-198-0013'])\n",
      "(1, 'sally', ['19-198-0013'])\n",
      "(1, 'say', ['19-198-0013'])\n",
      "(1, 'better', ['19-198-0013'])\n",
      "(1, 'means', ['19-198-0013'])\n",
      "(1, 'fable', ['19-198-0014'])\n",
      "(1, 'hare', ['19-198-0014'])\n",
      "(1, 'friends', ['19-198-0014'])\n",
      "(1, 'quickly', ['19-198-0014'])\n",
      "(1, 'england', ['19-198-0014'])\n",
      "(1, 'music', ['19-198-0014'])\n",
      "(1, 'sure', ['19-198-0014'])\n",
      "(1, 'tinkling', ['19-198-0014'])\n",
      "(1, 'keys', ['19-198-0014'])\n",
      "(1, 'forlorn', ['19-198-0014'])\n",
      "(1, 'spinnet', ['19-198-0014'])\n",
      "(1, 'eight', ['19-198-0015'])\n",
      "(1, 'insist', ['19-198-0015'])\n",
      "(1, 'accomplished', ['19-198-0015'])\n",
      "(1, 'spite', ['19-198-0015'])\n",
      "(1, 'incapacity', ['19-198-0015'])\n",
      "(1, 'distaste', ['19-198-0015'])\n",
      "(1, 'allowed', ['19-198-0015'])\n",
      "(1, 'leave', ['19-198-0015'])\n",
      "(1, 'off', ['19-198-0015'])\n",
      "(1, 'french', ['19-198-0016'])\n",
      "(1, 'proficiency', ['19-198-0016'])\n",
      "(1, 'either', ['19-198-0016'])\n",
      "(1, 'shirked', ['19-198-0016'])\n",
      "(1, 'lessons', ['19-198-0016'])\n",
      "(1, 'both', ['19-198-0016'])\n",
      "(1, 'whenever', ['19-198-0016'])\n",
      "(1, 'unaccountable', ['19-198-0016'])\n",
      "(1, 'these', ['19-198-0016'])\n",
      "(1, 'symptoms', ['19-198-0016'])\n",
      "(1, 'profligacy', ['19-198-0016'])\n",
      "(1, 'hated', ['19-198-0017'])\n",
      "(1, 'confinement', ['19-198-0017'])\n",
      "(1, 'cleanliness', ['19-198-0017'])\n",
      "(1, 'loved', ['19-198-0017'])\n",
      "(1, 'world', ['19-198-0017'])\n",
      "(1, 'rolling', ['19-198-0017'])\n",
      "(1, 'down', ['19-198-0017'])\n",
      "(1, 'green', ['19-198-0017'])\n",
      "(1, 'slope', ['19-198-0017'])\n",
      "(1, 'back', ['19-198-0017'])\n",
      "(1, 'house', ['19-198-0017'])\n",
      "(1, 'appearances', ['19-198-0017'])\n",
      "(1, 'mending', ['19-198-0017'])\n",
      "(1, 'curl', ['19-198-0018'])\n",
      "(1, 'long', ['19-198-0018'])\n",
      "(1, 'balls', ['19-198-0018'])\n",
      "(1, 'complexion', ['19-198-0018'])\n",
      "(1, 'improved', ['19-198-0018'])\n",
      "(1, 'softened', ['19-198-0018'])\n",
      "(1, 'plumpness', ['19-198-0018'])\n",
      "(1, 'colour', ['19-198-0018'])\n",
      "(1, 'eyes', ['19-198-0018'])\n",
      "(1, 'animation', ['19-198-0018'])\n",
      "(1, 'consequence', ['19-198-0018'])\n",
      "(1, 'dirt', ['19-198-0019'])\n",
      "(1, 'gave', ['19-198-0019'])\n",
      "(1, 'inclination', ['19-198-0019'])\n",
      "(1, 'finery', ['19-198-0019'])\n",
      "(1, 'clean', ['19-198-0019'])\n",
      "(1, 'smart', ['19-198-0019'])\n",
      "(1, 'hearing', ['19-198-0019'])\n",
      "(1, 'remark', ['19-198-0019'])\n",
      "(1, 'personal', ['19-198-0019'])\n",
      "(1, 'grows', ['19-198-0020'])\n",
      "(1, 'looking', ['19-198-0020'])\n",
      "(1, 'today', ['19-198-0020'])\n",
      "(1, 'words', ['19-198-0020'])\n",
      "(1, 'caught', ['19-198-0020'])\n",
      "(1, 'ears', ['19-198-0020'])\n",
      "(1, 'welcome', ['19-198-0020'])\n",
      "(1, 'sounds', ['19-198-0020'])\n",
      "(1, 'look', ['19-198-0020'])\n",
      "(1, 'beauty', ['19-198-0021'])\n",
      "(1, 'cradle', ['19-198-0021'])\n",
      "(1, 'can', ['19-198-0021'])\n",
      "(1, 'receive', ['19-198-0021'])\n",
      "(1, 'see', ['19-198-0021'])\n",
      "(1, 'everything', ['19-198-0021'])\n",
      "(1, 'ought', ['19-198-0021'])\n",
      "(1, 'time', ['19-198-0021'])\n",
      "(1, 'occupied', ['19-198-0021'])\n",
      "(1, 'lying', ['19-198-0021'])\n",
      "(1, 'ones', ['19-198-0021'])\n",
      "(1, 'elder', ['19-198-0022'])\n",
      "(1, 'inevitably', ['19-198-0022'])\n",
      "(1, 'left', ['19-198-0022'])\n",
      "(1, 'shift', ['19-198-0022'])\n",
      "(1, 'themselves', ['19-198-0022'])\n",
      "(1, 'wonderful', ['19-198-0022'])\n",
      "(1, 'nature', ['19-198-0022'])\n",
      "(1, 'prefer', ['19-198-0022'])\n",
      "(1, 'baseball', ['19-198-0022'])\n",
      "(1, 'riding', ['19-198-0022'])\n",
      "(1, 'horseback', ['19-198-0022'])\n",
      "(1, 'running', ['19-198-0023'])\n",
      "(1, 'country', ['19-198-0023'])\n",
      "(1, 'fourteen', ['19-198-0023'])\n",
      "(1, 'knowledge', ['19-198-0023'])\n",
      "(1, 'story', ['19-198-0023'])\n",
      "(1, 'reflection', ['19-198-0023'])\n",
      "(1, 'objection', ['19-198-0024'])\n",
      "(1, 'training', ['19-198-0024'])\n",
      "(1, 'works', ['19-198-0024'])\n",
      "(1, 'heroines', ['19-198-0024'])\n",
      "(1, 'supply', ['19-198-0024'])\n",
      "(1, 'memories', ['19-198-0024'])\n",
      "(1, 'quotations', ['19-198-0024'])\n",
      "(1, 'serviceable', ['19-198-0024'])\n",
      "(1, 'flower', ['19-198-0025'])\n",
      "(1, 'blush', ['19-198-0025'])\n",
      "(1, 'unseen', ['19-198-0025'])\n",
      "(1, 'waste', ['19-198-0025'])\n",
      "(1, 'its', ['19-198-0025'])\n",
      "(1, 'fragrance', ['19-198-0025'])\n",
      "(1, 'desert', ['19-198-0025'])\n",
      "(1, 'thompson', ['19-198-0025'])\n",
      "(1, 'delightful', ['19-198-0025'])\n",
      "(1, 'task', ['19-198-0025'])\n",
      "(1, 'teach', ['19-198-0025'])\n",
      "(1, 'idea', ['19-198-0025'])\n",
      "(1, 'shoot', ['19-198-0025'])\n",
      "(1, 'shakespeare', ['19-198-0026'])\n",
      "(1, 'store', ['19-198-0026'])\n",
      "(1, 'amongst', ['19-198-0026'])\n",
      "(1, 'rest', ['19-198-0026'])\n",
      "(1, 'trifles', ['19-198-0026'])\n",
      "(1, 'light', ['19-198-0026'])\n",
      "(1, 'jealous', ['19-198-0026'])\n",
      "(1, 'confirmation', ['19-198-0026'])\n",
      "(1, 'proofs', ['19-198-0026'])\n",
      "(1, 'holy', ['19-198-0026'])\n",
      "(1, 'writ', ['19-198-0026'])\n",
      "(1, 'beetle', ['19-198-0027'])\n",
      "(1, 'we', ['19-198-0027'])\n",
      "(1, 'tread', ['19-198-0027'])\n",
      "(1, 'corporal', ['19-198-0027'])\n",
      "(1, 'sufferance', ['19-198-0027'])\n",
      "(1, 'feels', ['19-198-0027'])\n",
      "(1, 'pang', ['19-198-0027'])\n",
      "(1, 'giant', ['19-198-0027'])\n",
      "(1, 'dies', ['19-198-0027'])\n",
      "(1, 'looks', ['19-198-0027'])\n",
      "(1, 'patience', ['19-198-0028'])\n",
      "(1, 'monument', ['19-198-0028'])\n",
      "(1, 'smiling', ['19-198-0028'])\n",
      "(1, 'grief', ['19-198-0028'])\n",
      "(1, 'far', ['19-198-0028'])\n",
      "(1, 'sufficient', ['19-198-0028'])\n",
      "(1, 'points', ['19-198-0028'])\n",
      "(1, 'came', ['19-198-0028'])\n",
      "(1, 'exceedingly', ['19-198-0028'])\n",
      "(1, 'write', ['19-198-0028'])\n",
      "(1, 'sonnets', ['19-198-0028'])\n",
      "(1, 'brought', ['19-198-0029'])\n",
      "(1, 'herself', ['19-198-0029'])\n",
      "(1, 'chance', ['19-198-0029'])\n",
      "(1, 'throwing', ['19-198-0029'])\n",
      "(1, 'whole', ['19-198-0029'])\n",
      "(1, 'party', ['19-198-0029'])\n",
      "(1, 'into', ['19-198-0029'])\n",
      "(1, 'raptures', ['19-198-0029'])\n",
      "(1, 'prelude', ['19-198-0029'])\n",
      "(1, 'pianoforte', ['19-198-0029'])\n",
      "(1, 'composition', ['19-198-0029'])\n",
      "(1, 'listen', ['19-198-0029'])\n",
      "(1, \"people's\", ['19-198-0029'])\n",
      "(1, 'performance', ['19-198-0029'])\n",
      "(1, 'fatigue', ['19-198-0029'])\n",
      "(1, 'greatest', ['19-198-0030'])\n",
      "(1, 'deficiency', ['19-198-0030'])\n",
      "(1, 'pencil', ['19-198-0030'])\n",
      "(1, 'notion', ['19-198-0030'])\n",
      "(1, 'drawing', ['19-198-0030'])\n",
      "(1, 'attempt', ['19-198-0030'])\n",
      "(1, 'sketch', ['19-198-0030'])\n",
      "(1, \"lover's\", ['19-198-0030'])\n",
      "(1, 'profile', ['19-198-0030'])\n",
      "(1, 'might', ['19-198-0030'])\n",
      "(1, 'detected', ['19-198-0030'])\n",
      "(1, 'design', ['19-198-0030'])\n",
      "(1, 'fell', ['19-198-0031'])\n",
      "(1, 'miserably', ['19-198-0031'])\n",
      "(1, 'short', ['19-198-0031'])\n",
      "(1, 'true', ['19-198-0031'])\n",
      "(1, 'height', ['19-198-0031'])\n",
      "(1, 'present', ['19-198-0031'])\n",
      "(1, 'know', ['19-198-0031'])\n",
      "(1, 'poverty', ['19-198-0031'])\n",
      "(1, 'lover', ['19-198-0031'])\n",
      "(1, 'portray', ['19-198-0031'])\n",
      "(1, 'reached', ['19-198-0031'])\n",
      "(1, 'amiable', ['19-198-0032'])\n",
      "(1, 'youth', ['19-198-0032'])\n",
      "(1, 'call', ['19-198-0032'])\n",
      "(1, 'forth', ['19-198-0032'])\n",
      "(1, 'sensibility', ['19-198-0032'])\n",
      "(1, 'inspired', ['19-198-0032'])\n",
      "(1, 'real', ['19-198-0032'])\n",
      "(1, 'passion', ['19-198-0032'])\n",
      "(1, 'excited', ['19-198-0032'])\n",
      "(1, 'admiration', ['19-198-0032'])\n",
      "(1, 'moderate', ['19-198-0032'])\n",
      "(1, 'transient', ['19-198-0032'])\n",
      "(1, 'things', ['19-198-0033'])\n",
      "(1, 'may', ['19-198-0033'])\n",
      "(1, 'generally', ['19-198-0033'])\n",
      "(1, 'accounted', ['19-198-0033'])\n",
      "(1, 'cause', ['19-198-0033'])\n",
      "(1, 'fairly', ['19-198-0033'])\n",
      "(1, 'searched', ['19-198-0033'])\n",
      "(1, 'out', ['19-198-0033'])\n",
      "(1, 'lord', ['19-198-0033'])\n",
      "(1, 'neighbourhood', ['19-198-0033'])\n",
      "(1, 'baronet', ['19-198-0033'])\n",
      "(1, 'family', ['19-198-0034'])\n",
      "(1, 'among', ['19-198-0034'])\n",
      "(1, 'acquaintance', ['19-198-0034'])\n",
      "(1, 'reared', ['19-198-0034'])\n",
      "(1, 'supported', ['19-198-0034'])\n",
      "(1, 'boy', ['19-198-0034'])\n",
      "(1, 'accidentally', ['19-198-0034'])\n",
      "(1, 'found', ['19-198-0034'])\n",
      "(1, 'door', ['19-198-0034'])\n",
      "(1, 'whose', ['19-198-0034'])\n",
      "(1, 'origin', ['19-198-0034'])\n",
      "(1, 'unknown', ['19-198-0034'])\n",
      "(1, 'ward', ['19-198-0034'])\n",
      "(1, 'squire', ['19-198-0034'])\n",
      "(1, 'parish', ['19-198-0034'])\n",
      "(1, 'perverseness', ['19-198-0035'])\n",
      "(1, 'forty', ['19-198-0035'])\n",
      "(1, 'surrounding', ['19-198-0035'])\n",
      "(1, 'families', ['19-198-0035'])\n",
      "(1, 'cannot', ['19-198-0035'])\n",
      "(1, 'prevent', ['19-198-0035'])\n",
      "(1, 'something', ['19-198-0035'])\n",
      "(1, 'will', ['19-198-0035'])\n",
      "(1, 'happen', ['19-198-0035'])\n",
      "(1, 'throw', ['19-198-0035'])\n",
      "(1, 'hero', ['19-198-0035'])\n",
      "(1, 'mister', ['19-198-0035'])\n",
      "(1, 'allen', ['19-198-0035'])\n",
      "(1, 'owned', ['19-198-0036'])\n",
      "(1, 'chief', ['19-198-0036'])\n",
      "(1, 'property', ['19-198-0036'])\n",
      "(1, 'fullerton', ['19-198-0036'])\n",
      "(1, 'village', ['19-198-0036'])\n",
      "(1, 'wiltshire', ['19-198-0036'])\n",
      "(1, 'lived', ['19-198-0036'])\n",
      "(1, 'ordered', ['19-198-0036'])\n",
      "(1, 'bath', ['19-198-0036'])\n",
      "(1, 'benefit', ['19-198-0036'])\n",
      "(1, 'gouty', ['19-198-0036'])\n",
      "(1, 'his', ['19-198-0036'])\n",
      "(1, 'humoured', ['19-198-0036'])\n",
      "(1, 'miss', ['19-198-0036'])\n",
      "(1, 'probably', ['19-198-0036'])\n",
      "(1, 'aware', ['19-198-0036'])\n",
      "(1, 'seek', ['19-198-0037'])\n",
      "(1, 'abroad', ['19-198-0037'])\n",
      "(1, 'invited', ['19-198-0037'])\n",
      "(1, 'go', ['19-198-0037'])\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# file_paths = [r'C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\19\\198\\19-198.trans.txt', \n",
    "#               r'C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\19\\227\\19-227.trans.txt',\n",
    "#               r'C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\26\\495\\26-495.trans.txt',\n",
    "#               r'C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\26\\496\\26-496.trans.txt']  # List of your txt files\n",
    "\n",
    "# file_paths = [r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\27\\123349\\27-123349.trans.txt\",\n",
    "#               r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\27\\124992\\27-124992.trans.txt\"]\n",
    "\n",
    "# file_paths = [r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\39\\121914\\39-121914.trans.txt\",\n",
    "#               r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\39\\121915\\39-121915.trans.txt\",\n",
    "#               r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\39\\121916\\39-121916.trans.txt\"]\n",
    "\n",
    "# file_paths = [r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\40\\222\\40-222.trans.txt\",\n",
    "#               r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\40\\121026\\40-121026.trans.txt\"]\n",
    "\n",
    "# file_paths = [r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\87\\121553\\87-121553.trans.txt\"]\n",
    "\n",
    "# file_paths = [r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\201\\122255\\201-122255.trans.txt\",\n",
    "#               r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\201\\127786\\201-127786.trans.txt\"]\n",
    "\n",
    "# file_paths = [r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\311\\124404\\311-124404.trans.txt\"]\n",
    "\n",
    "# file_paths = [r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\201\\122255\\201-122255.trans.txt\",\n",
    "#               r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\201\\127786\\201-127786.trans.txt\",\n",
    "#               r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\311\\124404\\311-124404.trans.txt\",\n",
    "# ]#              r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\87\\121553\\87-121553.trans.txt\"]\n",
    "\n",
    "# file_paths = [r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\87\\121553\\87-121553.trans.txt\"]\n",
    "file_paths = [r'C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\LibriSpeech\\train-clean-100\\19\\198\\19-198.trans.txt']\n",
    "spoken_words = count_word_occurrences(file_paths)\n",
    "\n",
    "for word in spoken_words:\n",
    "    print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized words: <s> and from shakespeare she gave a great store information <sil> among the rest that <sil> truffles light as air <sil> are <sil> to the jealous confirmation strong as proofs of holy writ </s>\n",
      "Extracted 'that' to 'C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words/that_no_extra_time/19/19-198-0026_1.wav' from 5150ms to 5540ms.\n",
      "Recognized words: <s> that [NOISE] <sil> that for a beetle which we tread upon in a court for all suffer and steals a pang as great as like a giant guys <sil> and that a young woman in love always looks </s>\n",
      "Extracted 'that' to 'C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words/that_no_extra_time/19/19-198-0027_1.wav' from 490ms to 960ms.\n",
      "Extracted 'that' to 'C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words/that_no_extra_time/19/19-198-0027_2.wav' from 1960ms to 2310ms.\n",
      "Extracted 'that' to 'C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words/that_no_extra_time/19/19-198-0027_3.wav' from 11340ms to 11630ms.\n",
      "Recognized words: <s> <sil> who are at the chief of the property about selected <sil> the village in welsh share of florida marlins live <sil> <sil> was born in to bat for the benefit of mentality constitution <sil> <sil> and his lady <sil> a good humored woman <sil> fond of this small island and probably aware that it </s>\n",
      "Extracted 'that' to 'C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words/that_no_extra_time/19/19-198-0036_1.wav' from 15340ms to 15590ms.\n",
      "Recognized words: <s> her greatest efficiency was a pencil <sil> <sil> she had no notion of drawing <sil> not enough <sil> even to attempt the sketch of her lovers profile <sil> that she might be detected in the design </s>\n",
      "Extracted 'that' to 'C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words/that_no_extra_time/19/19-198-0030_1.wav' from 9150ms to 9450ms.\n",
      "Recognized words: <s> [NOISE] her mother was the remarks <sil> in teaching her only to repeat <sil> the beggars petition <sil> and after all her next sister sally could say better than she did <sil> not get catherine was always stupid <sil> by no means </s>\n",
      "The word 'that' was not found in the audio C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/cleaned/19/198/19-198-0013.wav.\n",
      "Recognized words: <s> many of flour is more into flesh on the scene <sil> and waste is fragrance on the desert air <sil> from tom said that <sil> it is a delightful task to teach the young idea how to shoot </s>\n",
      "Extracted 'that' to 'C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words/that_no_extra_time/19/19-198-0025_1.wav' from 8580ms to 9010ms.\n",
      "Recognized words: <s> then reading about the country at the age of fourteen <sil> two books <sil> are at least books and information <sil> <sil> floor or provided that nothing like useful knowledge could be gained from them <sil> provided the overall story and no reflection </s>\n",
      "Extracted 'that' to 'C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words/that_no_extra_time/19/19-198-0023_1.wav' from 7910ms to 8270ms.\n",
      "Recognized words: <s> that er eller daughters who are inevitably left <sil> to shift for themselves <sil> and it was not very wonderful that catherine <sil> who had by nature nothing heroic about her <sil> <sil> should prefer cricket <sil> baseball <sil> riding on horseback </s>\n",
      "Extracted 'that' to 'C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words/that_no_extra_time/19/19-198-0022_1.wav' from 240ms to 510ms.\n",
      "Extracted 'that' to 'C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words/that_no_extra_time/19/19-198-0022_2.wav' from 6740ms to 7020ms.\n",
      "Recognized words: <s> [NOISE] the public are intriguing to bear in mind that thirteen years have passed <sil> since it was finished <sil> many maher said it was big on <sil> and that during that period places <sil> manners <sil> looks <sil> and opinions <sil> have undergone considerable changes </s>\n",
      "Extracted 'that' to 'C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words/that_no_extra_time/19/19-198-0003_1.wav' from 2600ms to 2900ms.\n",
      "Extracted 'that' to 'C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words/that_no_extra_time/19/19-198-0003_2.wav' from 8010ms to 8360ms.\n",
      "Extracted 'that' to 'C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words/that_no_extra_time/19/19-198-0003_3.wav' from 8620ms to 8920ms.\n"
     ]
    }
   ],
   "source": [
    "for word in spoken_words:\n",
    "    if word[1] == \"that\":\n",
    "        filenames = word[2]\n",
    "\n",
    "\n",
    "path_prefix = \"C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/cleaned\"\n",
    "# path_prefix = \"C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/as_wav\"\n",
    "\n",
    "files_to_search = [generate_path(filename, path_prefix) for filename in filenames]\n",
    "\n",
    "save_to_path = f\"C:/Computer Science Programs/Fall_2024/EE502_BioMed/project/data/extracted_words\"\n",
    "\n",
    "# please note word_extraction_wrapper will save to path/{word}_uncleaned/path/file \n",
    "word_extraction_wrapper(files_to_search, save_to_path, \"that\", 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized words: <s> when it was created was his mind to plead with such a living get a jade <sil> had in his mother heard a prophetic <sil> as soon as he espouses were completed between him and the face of holy followed <sil> with a with mutual safety dowry to other </s>\n",
      "The word 'that' was not found in the audio C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\as_wav\\87\\121553\\87-121553-0008.wav.\n"
     ]
    }
   ],
   "source": [
    "input = r'C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\as_wav\\87\\121553\\87-121553-0008.wav'\n",
    "extract_word_audio(input, \"./\", \"that\", 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioMed_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
