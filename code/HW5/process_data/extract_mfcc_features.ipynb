{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis,skew,mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths_by_subfolder(root):\n",
    "    file_dict = {}\n",
    "    \n",
    "    # Walk through the root directory\n",
    "    for subdir, _, files in os.walk(root):\n",
    "        # Get the subfolder name (last part of the path)\n",
    "        subfolder_name = os.path.basename(subdir)\n",
    "        file_pairs = [(os.path.join(subdir, file), os.path.splitext(file)[0]) for file in files]\n",
    "        \n",
    "        # Only add the subfolder if it has files\n",
    "        if file_pairs:\n",
    "            file_dict[subfolder_name] = file_pairs\n",
    "    \n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_mfcc(file_dictionary):\n",
    "#     mfcc_dict = {}\n",
    "    \n",
    "#     for reader in file_dictionary.keys():\n",
    "        \n",
    "#         if reader not in mfcc_dict:\n",
    "#             mfcc_dict[reader] = []\n",
    "\n",
    "#         for audio_path, filename_no_extension in file_dictionary[reader]:\n",
    "#             signal, sample_rate = librosa.load(audio_path, sr=None)\n",
    "#             mfcc_data = librosa.feature.mfcc(y=signal,sr=sample_rate)\n",
    "\n",
    "#             # Calculating various statistic measures on the coefficients.\n",
    "#             mean_mfcc = np.mean(mfcc_data, axis=1)\n",
    "#             median_mfcc= np.median(mfcc_data,axis=1)\n",
    "#             std_mfcc = np.std(mfcc_data, axis=1)\n",
    "#             skew_mfcc = skew(mfcc_data, axis=1)\n",
    "#             kurt_mfcc = kurtosis(mfcc_data, axis=1)\n",
    "#             maximum_mfcc = np.amax(mfcc_data, axis=1)\n",
    "#             minimum_mfcc = np.amin(mfcc_data, axis=1)\n",
    "            \n",
    "#             feature_list = np.concatenate((mean_mfcc,median_mfcc,std_mfcc,skew_mfcc,kurt_mfcc,maximum_mfcc,minimum_mfcc))\n",
    "#             mfcc_dict[reader].append((feature_list, filename_no_extension))\n",
    "\n",
    "#     with open(\"../../../data/extracted_features/mfcc_stats_that/mfcc_stats_that_v2.pickle\", \"wb\") as file:\n",
    "#         pickle.dump(mfcc_dict, file)\n",
    "\n",
    "def extract_mfcc(file_dictionary):\n",
    "    mfcc_dict = {}\n",
    "    \n",
    "    for reader in file_dictionary.keys():\n",
    "        \n",
    "        if reader not in mfcc_dict:\n",
    "            mfcc_dict[reader] = []\n",
    "\n",
    "        for audio_path, filename_no_extension in file_dictionary[reader]:\n",
    "            signal, sample_rate = librosa.load(audio_path, sr=None)\n",
    "            mfcc_data = librosa.feature.mfcc(y=signal, sr=sample_rate)\n",
    "\n",
    "            # Calculating various statistic measures on the MFCC coefficients\n",
    "            mean_mfcc = np.mean(mfcc_data, axis=1)\n",
    "            median_mfcc = np.median(mfcc_data, axis=1)\n",
    "            std_mfcc = np.std(mfcc_data, axis=1)\n",
    "            skew_mfcc = skew(mfcc_data, axis=1)\n",
    "            kurt_mfcc = kurtosis(mfcc_data, axis=1)\n",
    "            maximum_mfcc = np.amax(mfcc_data, axis=1)\n",
    "            minimum_mfcc = np.amin(mfcc_data, axis=1)\n",
    "\n",
    "            # Pitch extraction\n",
    "            f0, voiced_flag, voiced_probs = librosa.pyin(\n",
    "                signal, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')\n",
    "            )\n",
    "            \n",
    "            # Handle NaNs in pitch\n",
    "            if np.all(np.isnan(f0)):\n",
    "                mean_pitch, median_pitch = 0, 0  # Set default if no pitch is detected\n",
    "            else:\n",
    "                mean_pitch = np.nanmean(f0)  # Mean pitch, ignoring NaNs\n",
    "                median_pitch = np.nanmedian(f0)  # Median pitch, ignoring NaNs\n",
    "\n",
    "            # Concatenate all features\n",
    "            feature_list = np.concatenate((\n",
    "                mean_mfcc, median_mfcc, std_mfcc, skew_mfcc, kurt_mfcc, maximum_mfcc, minimum_mfcc,\n",
    "                [mean_pitch, median_pitch]  # Add pitch statistics to the feature list\n",
    "            ))\n",
    "            \n",
    "            mfcc_dict[reader].append((feature_list, filename_no_extension))\n",
    "\n",
    "    with open(\"../../../data/extracted_features/mfcc_stats_that/mfcc_stats_that_v2.pickle\", \"wb\") as file:\n",
    "        pickle.dump(mfcc_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['19', '201', '26', '27', '40', '87'])\n",
      "<class 'list'>\n",
      "[('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-198-0003.wav', '19-198-0003'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-198-0022.wav', '19-198-0022'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-198-0023.wav', '19-198-0023'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-198-0025.wav', '19-198-0025'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-198-0026.wav', '19-198-0026'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-198-0027.wav', '19-198-0027'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-198-0030.wav', '19-198-0030'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-198-0036.wav', '19-198-0036'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0000.wav', '19-227-0000'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0005.wav', '19-227-0005'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0007.wav', '19-227-0007'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0009.wav', '19-227-0009'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0015.wav', '19-227-0015'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0018.wav', '19-227-0018'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0025.wav', '19-227-0025'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0028.wav', '19-227-0028'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0039.wav', '19-227-0039'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0041.wav', '19-227-0041'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0052.wav', '19-227-0052'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0053.wav', '19-227-0053'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0054.wav', '19-227-0054'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0064.wav', '19-227-0064'), ('C:\\\\Computer Science Programs\\\\Fall_2024\\\\EE502_BioMed\\\\project\\\\data\\\\extracted_words\\\\that\\\\19\\\\19-227-0070.wav', '19-227-0070')]\n"
     ]
    }
   ],
   "source": [
    "file_dictionary = get_file_paths_by_subfolder(r\"C:\\Computer Science Programs\\Fall_2024\\EE502_BioMed\\project\\data\\extracted_words\\that\")\n",
    "print(file_dictionary.keys())\n",
    "print(type(file_dictionary[\"19\"]))\n",
    "print(file_dictionary[\"19\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_mfcc(file_dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioMed_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
